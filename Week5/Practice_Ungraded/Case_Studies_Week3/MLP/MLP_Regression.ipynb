{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP_Regression.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"lBPJEbHmmlS_","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"uJSPjgtDcVBa","colab_type":"text"},"cell_type":"markdown","source":["###Not for Grading"]},{"metadata":{"id":"giKRyJXKmpqL","colab_type":"text"},"cell_type":"markdown","source":["\n","####Regression using MLP with MSE Loss"]},{"metadata":{"id":"3iXTrneDmzN_","colab_type":"text"},"cell_type":"markdown","source":["The objective of this case study is to understand regression i.e., to predict the price of the house using Multilayer perceptron with Cross Entropy Loss.  The package used here is  [PyTorch](https://pytorch.org/). "]},{"metadata":{"id":"jdkRVbGhS26c","colab_type":"text"},"cell_type":"markdown","source":["##*We will see more on PyTorch in the upcoming sessions.*"]},{"metadata":{"id":"v1BKwE3rWi7j","colab_type":"text"},"cell_type":"markdown","source":["#### Setup Steps"]},{"metadata":{"id":"wsULhbIZWh3I","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P18_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IziqgHiFWg0B","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"912345678\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LpbyKaH3Wg44","colab_type":"code","cellView":"form","outputId":"88d76974-9200-4449-ed88-85b33038de3e","executionInfo":{"status":"ok","timestamp":1548762649308,"user_tz":-330,"elapsed":6831,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","\n","from IPython import get_ipython\n","ipython = get_ipython()\n","  \n","notebook=\"M1W2_CS_6_MLP_Regression\" #name of the notebook\n","\n","def setup():\n","    #ipython.magic(\"sx wget https://www.dropbox.com/s/vu7xkf6j3v9p5np/AIML_DS_REGR01_SIMPLEPENDULUMOSCILLATIONDATA.txt.zip?dl=1\")\n","   # ipython.magic(\"sx unzip AIML_DS_REGR01_SIMPLEPENDULUMOSCILLATIONDATA.txt.zip?dl=1\")\n","    ipython.magic(\"sx pip install torch\")\n","    print (\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(\"Please enter valid Id\")\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"id\" : Id, \"file_hash\" : file_hash, \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      print(\"Your submission is successful. Ref:\", submission_id)\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"rsciwGvITU-R","colab_type":"text"},"cell_type":"markdown","source":["### Importing required packages "]},{"metadata":{"id":"T2vxSk8VpJ0L","colab_type":"code","colab":{}},"cell_type":"code","source":["# Importing required Packages\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import  torch\n","from torch import nn\n","from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5ncXRJfzTYsL","colab_type":"text"},"cell_type":"markdown","source":["###The attributes of related House price are stored in \"X\" as features and the prices of the houses are stored in \"y\" as labels"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:34:08.691158Z","start_time":"2018-11-23T07:34:08.685467Z"},"id":"KhJrSQ0wmQDN","colab_type":"code","colab":{}},"cell_type":"code","source":["X = np.array([[3, 2000, 90], [2, 800, 143], [2, 850, 167], [1, 550, 267], [4, 2000, 396]])\n","y =  np.array([23.0, 8, 9.0, 9.0 , 25.0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ppxbl6p_Tj80","colab_type":"text"},"cell_type":"markdown","source":["###Standard scaling the features \"X\""]},{"metadata":{"id":"rUBlUjsLpxQC","colab_type":"code","outputId":"a044c8db-9e3e-4605-86c3-f1829b17f392","executionInfo":{"status":"ok","timestamp":1548762649652,"user_tz":-330,"elapsed":7150,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"cell_type":"code","source":["\n","ss = StandardScaler()\n","ss.fit(X)\n","X = ss.transform(X)\n","X"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n","  warnings.warn(msg, DataConversionWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n","  warnings.warn(msg, DataConversionWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([[ 0.58834841,  1.20863526, -1.13296108],\n","       [-0.39223227, -0.6997362 , -0.64318182],\n","       [-0.39223227, -0.62022073, -0.42139498],\n","       [-1.37281295, -1.09731359,  0.50271682],\n","       [ 1.56892908,  1.20863526,  1.69482106]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"BzA2wSs-Tne5","colab_type":"text"},"cell_type":"markdown","source":["###Defining the model for Linear Regression with MLP using PyTorch's nn.Module"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:32:33.885729Z","start_time":"2018-11-23T07:32:33.875066Z"},"id":"4NTCCccwmQEp","colab_type":"code","colab":{}},"cell_type":"code","source":["class LinearRegressionModel(nn.Module):\n","\n","    def __init__(self, input_dim, output_dim):\n","\n","        super(LinearRegressionModel, self).__init__() \n","        # Calling Super Class's constructor\n","        self.linear1 = nn.Linear(input_dim, 4)\n","        self.sigmoid = nn.Sigmoid()\n","        self.linear2 = nn.Linear(4, output_dim)\n","        # nn.Linear is defined in nn.Module\n","\n","    def forward(self, x):\n","        # Here the forward pass is simply a linear function\n","        #print(x.size())\n","        out = self.sigmoid(self.linear1(x))\n","        out = self.linear2(out)\n","        return out\n","\n","input_dim = 3\n","output_dim = 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AvshRKhrTuIV","colab_type":"text"},"cell_type":"markdown","source":["###The LinearRegressionModel() is saved in model below"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:33:14.943117Z","start_time":"2018-11-23T07:33:14.931903Z"},"id":"wQa8qRHemQEv","colab_type":"code","colab":{}},"cell_type":"code","source":["model = LinearRegressionModel(input_dim,output_dim)\n","criterion = nn.MSELoss()# Mean Squared Loss\n","l_rate = 0.01 #Learning Rate\n","optimiser = torch.optim.SGD(model.parameters(), lr = l_rate) #Stochastic Gradient Descent\n","\n","epochs = 500 #number of epochs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"to9oEE8yT1vb","colab_type":"text"},"cell_type":"markdown","source":["###Storing the losses in a list for the prescribed epochs"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:37:06.946827Z","start_time":"2018-11-23T07:37:06.921324Z"},"scrolled":false,"id":"Tm7a9HyXmQE1","colab_type":"code","outputId":"0af1f1c8-69fa-4924-9698-958be8b7bfe9","executionInfo":{"status":"ok","timestamp":1548762650455,"user_tz":-330,"elapsed":7903,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":27217}},"cell_type":"code","source":["losses = []\n","for epoch in range(epochs):\n","#increase the number of epochs by 1 every time\n","    epoch +=1\n","    inputs = torch.from_numpy(X.astype(np.float32))\n","    labels = torch.from_numpy(y.astype(np.float32))\n","    #clear grads as discussed in prev post\n","    optimiser.zero_grad()\n","    #forward to get predicted values\n","    outputs = model.forward(inputs)\n","    #print('outputs: ', outputs.size())\n","    #print('labels: ', labels.size())\n","    loss = criterion(outputs, labels.unsqueeze(1))\n","    loss.backward()# back props\n","    optimiser.step()# update the parameters\n","    print('epoch {}, loss {}'.format(epoch,loss.item()))\n","    losses.append(loss.item())\n","    if (epoch-1)%5 == 0:\n","        for i in model.parameters():\n","            print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch 1, loss 270.5562438964844\n","Parameter containing:\n","tensor([[-0.5207, -0.1809, -0.3724],\n","        [ 0.2014, -0.4952,  0.1644],\n","        [-0.5724, -0.5533, -0.4923],\n","        [-0.3977, -0.1508,  0.5466]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1835, -0.3697,  0.1594, -0.5372], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.1821,  0.6076, -0.0767,  0.1073]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3556], requires_grad=True)\n","epoch 2, loss 256.47845458984375\n","epoch 3, loss 243.30499267578125\n","epoch 4, loss 230.87454223632812\n","epoch 5, loss 219.05223083496094\n","epoch 6, loss 207.72604370117188\n","Parameter containing:\n","tensor([[-0.4696, -0.1162, -0.3762],\n","        [ 0.3331, -0.3589,  0.2289],\n","        [-0.5610, -0.5356, -0.5015],\n","        [-0.3546, -0.1103,  0.5779]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2976, -0.1197,  0.1909, -0.4588], requires_grad=True)\n","Parameter containing:\n","tensor([[0.7864, 1.1450, 0.4620, 0.5614]], requires_grad=True)\n","Parameter containing:\n","tensor([1.6659], requires_grad=True)\n","epoch 7, loss 196.80636596679688\n","epoch 8, loss 186.22654724121094\n","epoch 9, loss 175.94192504882812\n","epoch 10, loss 165.92617797851562\n","epoch 11, loss 156.16641235351562\n","Parameter containing:\n","tensor([[-0.3238,  0.0504, -0.3434],\n","        [ 0.5352, -0.1295,  0.2797],\n","        [-0.5052, -0.4542, -0.5313],\n","        [-0.2407,  0.0013,  0.6485]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5281,  0.2183,  0.3086, -0.2926], requires_grad=True)\n","Parameter containing:\n","tensor([[1.3228, 1.7145, 0.8883, 0.9758]], requires_grad=True)\n","Parameter containing:\n","tensor([2.7393], requires_grad=True)\n","epoch 12, loss 146.66009521484375\n","epoch 13, loss 137.41604614257812\n","epoch 14, loss 128.4583740234375\n","epoch 15, loss 119.82972717285156\n","epoch 16, loss 111.58794403076172\n","Parameter containing:\n","tensor([[-0.0850,  0.2984, -0.2266],\n","        [ 0.7200,  0.1147,  0.2505],\n","        [-0.4000, -0.3154, -0.5496],\n","        [-0.0827,  0.1708,  0.7143]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.8105,  0.5317,  0.4673, -0.0900], requires_grad=True)\n","Parameter containing:\n","tensor([[1.8423, 2.2910, 1.2338, 1.3779]], requires_grad=True)\n","Parameter containing:\n","tensor([3.5859], requires_grad=True)\n","epoch 17, loss 103.7933120727539\n","epoch 18, loss 96.4914779663086\n","epoch 19, loss 89.70203399658203\n","epoch 20, loss 83.41817474365234\n","epoch 21, loss 77.61408233642578\n","Parameter containing:\n","tensor([[ 0.1312,  0.5237, -0.1127],\n","        [ 0.8643,  0.3235,  0.1981],\n","        [-0.2425, -0.1310, -0.5177],\n","        [ 0.0748,  0.3657,  0.7264]], requires_grad=True)\n","Parameter containing:\n","tensor([1.0292, 0.7449, 0.6378, 0.0966], requires_grad=True)\n","Parameter containing:\n","tensor([[2.3352, 2.8076, 1.5206, 1.7560]], requires_grad=True)\n","Parameter containing:\n","tensor([4.2232], requires_grad=True)\n","epoch 22, loss 72.25403594970703\n","epoch 23, loss 67.29984283447266\n","epoch 24, loss 62.715824127197266\n","epoch 25, loss 58.47164535522461\n","epoch 26, loss 54.54341125488281\n","Parameter containing:\n","tensor([[ 0.2826,  0.6952, -0.0451],\n","        [ 0.9828,  0.4999,  0.1671],\n","        [-0.0410,  0.0827, -0.4192],\n","        [ 0.2174,  0.5653,  0.6948]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1430, 0.8517, 0.7995, 0.2403], requires_grad=True)\n","Parameter containing:\n","tensor([[2.7500, 3.2353, 1.7746, 2.0950]], requires_grad=True)\n","Parameter containing:\n","tensor([4.6883], requires_grad=True)\n","epoch 27, loss 50.91273498535156\n","epoch 28, loss 47.5646858215332\n","epoch 29, loss 44.485008239746094\n","epoch 30, loss 41.65805435180664\n","epoch 31, loss 39.06596374511719\n","Parameter containing:\n","tensor([[ 0.3987,  0.8393,  0.0042],\n","        [ 1.0865,  0.6576,  0.1624],\n","        [ 0.1531,  0.2842, -0.3020],\n","        [ 0.3416,  0.7523,  0.6534]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1787, 0.8777, 0.9189, 0.3328], requires_grad=True)\n","Parameter containing:\n","tensor([[3.0798, 3.5787, 2.0110, 2.3901]], requires_grad=True)\n","Parameter containing:\n","tensor([5.0226], requires_grad=True)\n","epoch 32, loss 36.68911361694336\n","epoch 33, loss 34.50716018676758\n","epoch 34, loss 32.500125885009766\n","epoch 35, loss 30.649261474609375\n","epoch 36, loss 28.937543869018555\n","Parameter containing:\n","tensor([[ 0.4947,  0.9692,  0.0512],\n","        [ 1.1788,  0.8027,  0.1780],\n","        [ 0.3005,  0.4457, -0.2114],\n","        [ 0.4459,  0.9167,  0.6224]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1635, 0.8517, 0.9797, 0.3804], requires_grad=True)\n","Parameter containing:\n","tensor([[3.3426, 3.8565, 2.2222, 2.6441]], requires_grad=True)\n","Parameter containing:\n","tensor([5.2652], requires_grad=True)\n","epoch 37, loss 27.3498477935791\n","epoch 38, loss 25.872905731201172\n","epoch 39, loss 24.495269775390625\n","epoch 40, loss 23.20702362060547\n","epoch 41, loss 21.999658584594727\n","Parameter containing:\n","tensor([[ 0.5760,  1.0884,  0.1004],\n","        [ 1.2602,  0.9359,  0.2065],\n","        [ 0.4090,  0.5748, -0.1428],\n","        [ 0.5319,  1.0573,  0.6057]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1180, 0.7972, 0.9979, 0.3968], requires_grad=True)\n","Parameter containing:\n","tensor([[3.5581, 4.0873, 2.4040, 2.8634]], requires_grad=True)\n","Parameter containing:\n","tensor([5.4469], requires_grad=True)\n","epoch 42, loss 20.86585235595703\n","epoch 43, loss 19.799283981323242\n","epoch 44, loss 18.794490814208984\n","epoch 45, loss 17.846729278564453\n","epoch 46, loss 16.951828002929688\n","Parameter containing:\n","tensor([[ 0.6446,  1.1969,  0.1515],\n","        [ 1.3311,  1.0560,  0.2410],\n","        [ 0.4913,  0.6819, -0.0858],\n","        [ 0.6021,  1.1765,  0.6001]], requires_grad=True)\n","Parameter containing:\n","tensor([1.0571, 0.7306, 0.9910, 0.3948], requires_grad=True)\n","Parameter containing:\n","tensor([[3.7399, 4.2836, 2.5603, 3.0539]], requires_grad=True)\n","Parameter containing:\n","tensor([5.5884], requires_grad=True)\n","epoch 47, loss 16.10613441467285\n","epoch 48, loss 15.306398391723633\n","epoch 49, loss 14.54971981048584\n","epoch 50, loss 13.833480834960938\n","epoch 51, loss 13.15530014038086\n","Parameter containing:\n","tensor([[ 0.7021,  1.2943,  0.2025],\n","        [ 1.3919,  1.1624,  0.2766],\n","        [ 0.5553,  0.7729, -0.0351],\n","        [ 0.6592,  1.2775,  0.6021]], requires_grad=True)\n","Parameter containing:\n","tensor([0.9907, 0.6621, 0.9701, 0.3828], requires_grad=True)\n","Parameter containing:\n","tensor([[3.8964, 4.4532, 2.6954, 3.2199]], requires_grad=True)\n","Parameter containing:\n","tensor([5.7021], requires_grad=True)\n","epoch 52, loss 12.513005256652832\n","epoch 53, loss 11.90459156036377\n","epoch 54, loss 11.328216552734375\n","epoch 55, loss 10.782142639160156\n","epoch 56, loss 10.264762878417969\n","Parameter containing:\n","tensor([[0.7501, 1.3809, 0.2514],\n","        [1.4439, 1.2554, 0.3105],\n","        [0.6058, 0.8511, 0.0116],\n","        [0.7058, 1.3631, 0.6087]], requires_grad=True)\n","Parameter containing:\n","tensor([0.9248, 0.5971, 0.9419, 0.3660], requires_grad=True)\n","Parameter containing:\n","tensor([[4.0325, 4.6006, 2.8129, 3.3648]], requires_grad=True)\n","Parameter containing:\n","tensor([5.7959], requires_grad=True)\n","epoch 57, loss 9.774565696716309\n","epoch 58, loss 9.310124397277832\n","epoch 59, loss 8.870081901550293\n","epoch 60, loss 8.453182220458984\n","epoch 61, loss 8.058204650878906\n","Parameter containing:\n","tensor([[0.7900, 1.4570, 0.2972],\n","        [1.4880, 1.3361, 0.3417],\n","        [0.6460, 0.9188, 0.0552],\n","        [0.7438, 1.4357, 0.6181]], requires_grad=True)\n","Parameter containing:\n","tensor([0.8626, 0.5377, 0.9104, 0.3472], requires_grad=True)\n","Parameter containing:\n","tensor([[4.1513, 4.7290, 2.9153, 3.4911]], requires_grad=True)\n","Parameter containing:\n","tensor([5.8744], requires_grad=True)\n","epoch 62, loss 7.684013843536377\n","epoch 63, loss 7.329517364501953\n","epoch 64, loss 6.993687629699707\n","epoch 65, loss 6.675551414489746\n","epoch 66, loss 6.374171257019043\n","Parameter containing:\n","tensor([[0.8231, 1.5234, 0.3394],\n","        [1.5255, 1.4059, 0.3700],\n","        [0.6780, 0.9776, 0.0961],\n","        [0.7749, 1.4976, 0.6292]], requires_grad=True)\n","Parameter containing:\n","tensor([0.8054, 0.4843, 0.8781, 0.3280], requires_grad=True)\n","Parameter containing:\n","tensor([[4.2550, 4.8410, 3.0044, 3.6011]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9407], requires_grad=True)\n","epoch 67, loss 6.088668346405029\n","epoch 68, loss 5.818196773529053\n","epoch 69, loss 5.561967372894287\n","epoch 70, loss 5.319218158721924\n","epoch 71, loss 5.089229583740234\n","Parameter containing:\n","tensor([[0.8505, 1.5813, 0.3780],\n","        [1.5574, 1.4662, 0.3955],\n","        [0.7036, 1.0287, 0.1345],\n","        [0.8004, 1.5504, 0.6412]], requires_grad=True)\n","Parameter containing:\n","tensor([0.7538, 0.4367, 0.8462, 0.3091], requires_grad=True)\n","Parameter containing:\n","tensor([[4.3456, 4.9384, 3.0820, 3.6968]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9971], requires_grad=True)\n","epoch 72, loss 4.871318817138672\n","epoch 73, loss 4.664842128753662\n","epoch 74, loss 4.4691877365112305\n","epoch 75, loss 4.283762454986572\n","epoch 76, loss 4.108019828796387\n","Parameter containing:\n","tensor([[0.8732, 1.6317, 0.4132],\n","        [1.5847, 1.5185, 0.4186],\n","        [0.7238, 1.0732, 0.1706],\n","        [0.8213, 1.5956, 0.6538]], requires_grad=True)\n","Parameter containing:\n","tensor([0.7074, 0.3942, 0.8156, 0.2909], requires_grad=True)\n","Parameter containing:\n","tensor([[4.4245, 5.0230, 3.1495, 3.7800]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0453], requires_grad=True)\n","epoch 77, loss 3.9414424896240234\n","epoch 78, loss 3.783529043197632\n","epoch 79, loss 3.6338109970092773\n","epoch 80, loss 3.4918386936187744\n","epoch 81, loss 3.3571994304656982\n","Parameter containing:\n","tensor([[0.8919, 1.6754, 0.4455],\n","        [1.6080, 1.5639, 0.4396],\n","        [0.7397, 1.1119, 0.2047],\n","        [0.8383, 1.6344, 0.6667]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6658, 0.3563, 0.7868, 0.2737], requires_grad=True)\n","Parameter containing:\n","tensor([[4.4933, 5.0966, 3.2081, 3.8522]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0867], requires_grad=True)\n","epoch 82, loss 3.2294938564300537\n","epoch 83, loss 3.1083383560180664\n","epoch 84, loss 2.993380069732666\n","epoch 85, loss 2.884284734725952\n","epoch 86, loss 2.7807319164276123\n","Parameter containing:\n","tensor([[0.9072, 1.7134, 0.4751],\n","        [1.6280, 1.6034, 0.4588],\n","        [0.7518, 1.1454, 0.2369],\n","        [0.8521, 1.6677, 0.6797]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6286, 0.3222, 0.7598, 0.2574], requires_grad=True)\n","Parameter containing:\n","tensor([[4.5531, 5.1605, 3.2590, 3.9150]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1224], requires_grad=True)\n","epoch 87, loss 2.68241548538208\n","epoch 88, loss 2.58905291557312\n","epoch 89, loss 2.500377893447876\n","epoch 90, loss 2.416131019592285\n","epoch 91, loss 2.3360755443573\n","Parameter containing:\n","tensor([[0.9196, 1.7465, 0.5025],\n","        [1.6453, 1.6380, 0.4766],\n","        [0.7608, 1.1745, 0.2674],\n","        [0.8632, 1.6964, 0.6928]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5953, 0.2914, 0.7349, 0.2421], requires_grad=True)\n","Parameter containing:\n","tensor([[4.6052, 5.2161, 3.3031, 3.9695]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1533], requires_grad=True)\n","epoch 92, loss 2.259977340698242\n","epoch 93, loss 2.1876275539398193\n","epoch 94, loss 2.1188201904296875\n","epoch 95, loss 2.053366184234619\n","epoch 96, loss 1.9910809993743896\n","Parameter containing:\n","tensor([[0.9296, 1.7753, 0.5279],\n","        [1.6602, 1.6684, 0.4931],\n","        [0.7672, 1.1997, 0.2963],\n","        [0.8720, 1.7210, 0.7057]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5652, 0.2635, 0.7119, 0.2278], requires_grad=True)\n","Parameter containing:\n","tensor([[4.6504, 5.2643, 3.3414, 4.0169]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1803], requires_grad=True)\n","epoch 97, loss 1.9317938089370728\n","epoch 98, loss 1.875344157218933\n","epoch 99, loss 1.8215802907943726\n","epoch 100, loss 1.770353078842163\n","epoch 101, loss 1.7215319871902466\n","Parameter containing:\n","tensor([[0.9375, 1.8003, 0.5516],\n","        [1.6731, 1.6951, 0.5085],\n","        [0.7713, 1.2214, 0.3239],\n","        [0.8789, 1.7423, 0.7186]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5381, 0.2380, 0.6907, 0.2145], requires_grad=True)\n","Parameter containing:\n","tensor([[4.6899, 5.3063, 3.3747, 4.0582]], requires_grad=True)\n","Parameter containing:\n","tensor([6.2039], requires_grad=True)\n","epoch 102, loss 1.6749833822250366\n","epoch 103, loss 1.6305873394012451\n","epoch 104, loss 1.5882295370101929\n","epoch 105, loss 1.5477988719940186\n","epoch 106, loss 1.5091981887817383\n","Parameter containing:\n","tensor([[0.9436, 1.8222, 0.5739],\n","        [1.6843, 1.7188, 0.5229],\n","        [0.7733, 1.2400, 0.3502],\n","        [0.8842, 1.7607, 0.7313]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5136, 0.2147, 0.6714, 0.2020], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7242, 5.3428, 3.4036, 4.0942]], requires_grad=True)\n","Parameter containing:\n","tensor([6.2248], requires_grad=True)\n","epoch 107, loss 1.4723283052444458\n","epoch 108, loss 1.4370934963226318\n","epoch 109, loss 1.403411865234375\n","epoch 110, loss 1.3711986541748047\n","epoch 111, loss 1.3403822183609009\n","Parameter containing:\n","tensor([[0.9483, 1.8413, 0.5948],\n","        [1.6941, 1.7398, 0.5365],\n","        [0.7737, 1.2560, 0.3754],\n","        [0.8880, 1.7765, 0.7438]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4914, 0.1932, 0.6536, 0.1903], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7542, 5.3747, 3.4288, 4.1256]], requires_grad=True)\n","Parameter containing:\n","tensor([6.2435], requires_grad=True)\n","epoch 112, loss 1.310882568359375\n","epoch 113, loss 1.2826368808746338\n","epoch 114, loss 1.2555772066116333\n","epoch 115, loss 1.2296411991119385\n","epoch 116, loss 1.20477294921875\n","Parameter containing:\n","tensor([[0.9516, 1.8580, 0.6147],\n","        [1.7027, 1.7586, 0.5493],\n","        [0.7725, 1.2695, 0.3996],\n","        [0.8907, 1.7902, 0.7561]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4711, 0.1734, 0.6375, 0.1794], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7805, 5.4025, 3.4508, 4.1531]], requires_grad=True)\n","Parameter containing:\n","tensor([6.2603], requires_grad=True)\n","epoch 117, loss 1.1809154748916626\n","epoch 118, loss 1.158017873764038\n","epoch 119, loss 1.136030912399292\n","epoch 120, loss 1.1149075031280518\n","epoch 121, loss 1.0946062803268433\n","Parameter containing:\n","tensor([[0.9538, 1.8726, 0.6335],\n","        [1.7102, 1.7754, 0.5615],\n","        [0.7700, 1.2810, 0.4229],\n","        [0.8923, 1.8020, 0.7682]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4525, 0.1550, 0.6227, 0.1693], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8034, 5.4269, 3.4700, 4.1773]], requires_grad=True)\n","Parameter containing:\n","tensor([6.2756], requires_grad=True)\n","epoch 122, loss 1.0750834941864014\n","epoch 123, loss 1.0563002824783325\n","epoch 124, loss 1.0382205247879028\n","epoch 125, loss 1.020806074142456\n","epoch 126, loss 1.0040276050567627\n","Parameter containing:\n","tensor([[0.9551, 1.8854, 0.6514],\n","        [1.7169, 1.7906, 0.5731],\n","        [0.7664, 1.2906, 0.4454],\n","        [0.8930, 1.8122, 0.7801]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4355, 0.1379, 0.6093, 0.1598], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8236, 5.4483, 3.4869, 4.1985]], requires_grad=True)\n","Parameter containing:\n","tensor([6.2895], requires_grad=True)\n","epoch 127, loss 0.9878538250923157\n","epoch 128, loss 0.9722505807876587\n","epoch 129, loss 0.9571946263313293\n","epoch 130, loss 0.9426569938659668\n","epoch 131, loss 0.9286122918128967\n","Parameter containing:\n","tensor([[0.9555, 1.8967, 0.6686],\n","        [1.7227, 1.8043, 0.5841],\n","        [0.7617, 1.2986, 0.4671],\n","        [0.8930, 1.8210, 0.7918]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4199, 0.1219, 0.5971, 0.1509], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8414, 5.4671, 3.5017, 4.2173]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3024], requires_grad=True)\n","epoch 132, loss 0.9150382876396179\n","epoch 133, loss 0.9019111394882202\n","epoch 134, loss 0.8892093300819397\n","epoch 135, loss 0.8769136071205139\n","epoch 136, loss 0.8650046586990356\n","Parameter containing:\n","tensor([[0.9552, 1.9066, 0.6850],\n","        [1.7279, 1.8167, 0.5946],\n","        [0.7561, 1.3051, 0.4882],\n","        [0.8923, 1.8287, 0.8031]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4055, 0.1069, 0.5860, 0.1427], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8571, 5.4837, 3.5148, 4.2338]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3144], requires_grad=True)\n","epoch 137, loss 0.8534632325172424\n","epoch 138, loss 0.8422749638557434\n","epoch 139, loss 0.8314208388328552\n","epoch 140, loss 0.8208861947059631\n","epoch 141, loss 0.8106557130813599\n","Parameter containing:\n","tensor([[0.9544, 1.9153, 0.7007],\n","        [1.7326, 1.8281, 0.6046],\n","        [0.7498, 1.3104, 0.5086],\n","        [0.8910, 1.8353, 0.8143]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3922, 0.0929, 0.5760, 0.1349], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8710, 5.4983, 3.5264, 4.2486]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3256], requires_grad=True)\n","epoch 142, loss 0.8007174134254456\n","epoch 143, loss 0.7910580635070801\n","epoch 144, loss 0.781663715839386\n","epoch 145, loss 0.7725237607955933\n","epoch 146, loss 0.7636262774467468\n","Parameter containing:\n","tensor([[0.9530, 1.9231, 0.7159],\n","        [1.7368, 1.8386, 0.6141],\n","        [0.7427, 1.3146, 0.5285],\n","        [0.8893, 1.8411, 0.8251]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3798, 0.0796, 0.5669, 0.1277], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8834, 5.5114, 3.5368, 4.2617]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3362], requires_grad=True)\n","epoch 147, loss 0.7549611330032349\n","epoch 148, loss 0.7465184926986694\n","epoch 149, loss 0.7382883429527283\n","epoch 150, loss 0.7302613258361816\n","epoch 151, loss 0.7224298119544983\n","Parameter containing:\n","tensor([[0.9512, 1.9300, 0.7304],\n","        [1.7405, 1.8483, 0.6233],\n","        [0.7350, 1.3178, 0.5478],\n","        [0.8872, 1.8461, 0.8357]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3684, 0.0672, 0.5586, 0.1210], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8944, 5.5230, 3.5461, 4.2734]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3462], requires_grad=True)\n","epoch 152, loss 0.7147857546806335\n","epoch 153, loss 0.707320511341095\n","epoch 154, loss 0.7000276446342468\n","epoch 155, loss 0.6928992867469788\n","epoch 156, loss 0.6859297156333923\n","Parameter containing:\n","tensor([[0.9490, 1.9361, 0.7445],\n","        [1.7440, 1.8574, 0.6320],\n","        [0.7268, 1.3201, 0.5666],\n","        [0.8848, 1.8505, 0.8461]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3577, 0.0553, 0.5512, 0.1148], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9043, 5.5334, 3.5545, 4.2840]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3557], requires_grad=True)\n","epoch 157, loss 0.6791121959686279\n","epoch 158, loss 0.6724405288696289\n","epoch 159, loss 0.6659103035926819\n","epoch 160, loss 0.6595147252082825\n","epoch 161, loss 0.6532485485076904\n","Parameter containing:\n","tensor([[0.9465, 1.9416, 0.7580],\n","        [1.7471, 1.8659, 0.6404],\n","        [0.7180, 1.3217, 0.5849],\n","        [0.8821, 1.8544, 0.8561]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3478, 0.0441, 0.5445, 0.1090], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9132, 5.5427, 3.5620, 4.2935]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3648], requires_grad=True)\n","epoch 162, loss 0.6471084952354431\n","epoch 163, loss 0.6410887837409973\n","epoch 164, loss 0.6351849436759949\n","epoch 165, loss 0.6293929815292358\n","epoch 166, loss 0.6237096786499023\n","Parameter containing:\n","tensor([[0.9437, 1.9466, 0.7710],\n","        [1.7501, 1.8739, 0.6483],\n","        [0.7089, 1.3226, 0.6028],\n","        [0.8792, 1.8579, 0.8659]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3386, 0.0335, 0.5386, 0.1035], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9212, 5.5511, 3.5689, 4.3021]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3734], requires_grad=True)\n","epoch 167, loss 0.6181303858757019\n","epoch 168, loss 0.6126518845558167\n","epoch 169, loss 0.6072705984115601\n","epoch 170, loss 0.6019840240478516\n","epoch 171, loss 0.5967874526977539\n","Parameter containing:\n","tensor([[0.9408, 1.9512, 0.7836],\n","        [1.7528, 1.8815, 0.6560],\n","        [0.6994, 1.3230, 0.6203],\n","        [0.8761, 1.8611, 0.8753]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3299, 0.0234, 0.5332, 0.0985], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9285, 5.5587, 3.5752, 4.3099]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3818], requires_grad=True)\n","epoch 172, loss 0.5916785597801208\n","epoch 173, loss 0.5866555571556091\n","epoch 174, loss 0.5817142128944397\n","epoch 175, loss 0.5768533945083618\n","epoch 176, loss 0.5720699429512024\n","Parameter containing:\n","tensor([[0.9377, 1.9554, 0.7958],\n","        [1.7553, 1.8887, 0.6633],\n","        [0.6896, 1.3229, 0.6374],\n","        [0.8729, 1.8639, 0.8845]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3218, 0.0138, 0.5285, 0.0938], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9351, 5.5656, 3.5810, 4.3170]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3897], requires_grad=True)\n","epoch 177, loss 0.567361056804657\n","epoch 178, loss 0.5627259016036987\n","epoch 179, loss 0.5581604242324829\n","epoch 180, loss 0.5536646842956543\n","epoch 181, loss 0.5492352843284607\n","Parameter containing:\n","tensor([[0.9345, 1.9593, 0.8075],\n","        [1.7578, 1.8957, 0.6702],\n","        [0.6795, 1.3225, 0.6541],\n","        [0.8696, 1.8666, 0.8934]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3142, 0.0046, 0.5243, 0.0894], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9412, 5.5719, 3.5863, 4.3236]], requires_grad=True)\n","Parameter containing:\n","tensor([6.3974], requires_grad=True)\n","epoch 182, loss 0.5448707342147827\n","epoch 183, loss 0.5405697226524353\n","epoch 184, loss 0.5363291501998901\n","epoch 185, loss 0.5321494340896606\n","epoch 186, loss 0.5280278921127319\n","Parameter containing:\n","tensor([[0.9312, 1.9629, 0.8189],\n","        [1.7601, 1.9024, 0.6769],\n","        [0.6691, 1.3216, 0.6704],\n","        [0.8663, 1.8691, 0.9020]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3070, -0.0041,  0.5207,  0.0854], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9468, 5.5777, 3.5913, 4.3296]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4047], requires_grad=True)\n","epoch 187, loss 0.5239629149436951\n","epoch 188, loss 0.5199538469314575\n","epoch 189, loss 0.5159984230995178\n","epoch 190, loss 0.5120957493782043\n","epoch 191, loss 0.5082442164421082\n","Parameter containing:\n","tensor([[0.9279, 1.9664, 0.8298],\n","        [1.7623, 1.9090, 0.6832],\n","        [0.6586, 1.3205, 0.6863],\n","        [0.8629, 1.8715, 0.9104]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3003, -0.0125,  0.5175,  0.0817], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9519, 5.5830, 3.5959, 4.3351]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4117], requires_grad=True)\n","epoch 192, loss 0.5044436454772949\n","epoch 193, loss 0.500691831111908\n","epoch 194, loss 0.4969877600669861\n","epoch 195, loss 0.4933311641216278\n","epoch 196, loss 0.48972001671791077\n","Parameter containing:\n","tensor([[0.9245, 1.9697, 0.8404],\n","        [1.7645, 1.9153, 0.6893],\n","        [0.6479, 1.3192, 0.7020],\n","        [0.8595, 1.8738, 0.9184]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2940, -0.0205,  0.5148,  0.0782], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9566, 5.5879, 3.6002, 4.3402]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4184], requires_grad=True)\n","epoch 197, loss 0.4861539900302887\n","epoch 198, loss 0.48263242840766907\n","epoch 199, loss 0.47915321588516235\n","epoch 200, loss 0.4757167398929596\n","epoch 201, loss 0.4723213016986847\n","Parameter containing:\n","tensor([[0.9211, 1.9729, 0.8507],\n","        [1.7666, 1.9216, 0.6950],\n","        [0.6371, 1.3176, 0.7172],\n","        [0.8561, 1.8760, 0.9261]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2880, -0.0281,  0.5125,  0.0750], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9611, 5.5925, 3.6043, 4.3450]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4248], requires_grad=True)\n","epoch 202, loss 0.468966007232666\n","epoch 203, loss 0.4656508266925812\n","epoch 204, loss 0.46237483620643616\n","epoch 205, loss 0.45913705229759216\n","epoch 206, loss 0.455936461687088\n","Parameter containing:\n","tensor([[0.9178, 1.9761, 0.8605],\n","        [1.7687, 1.9277, 0.7005],\n","        [0.6262, 1.3160, 0.7322],\n","        [0.8527, 1.8783, 0.9336]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2824, -0.0354,  0.5107,  0.0721], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9652, 5.5967, 3.6082, 4.3494]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4310], requires_grad=True)\n","epoch 207, loss 0.45277270674705505\n","epoch 208, loss 0.4496454894542694\n","epoch 209, loss 0.44655340909957886\n","epoch 210, loss 0.4434961974620819\n","epoch 211, loss 0.440473347902298\n","Parameter containing:\n","tensor([[0.9145, 1.9792, 0.8701],\n","        [1.7708, 1.9338, 0.7058],\n","        [0.6152, 1.3142, 0.7468],\n","        [0.8494, 1.8805, 0.9407]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2771, -0.0425,  0.5091,  0.0694], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9690, 5.6007, 3.6118, 4.3535]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4368], requires_grad=True)\n","epoch 212, loss 0.43748417496681213\n","epoch 213, loss 0.4345284402370453\n","epoch 214, loss 0.43160468339920044\n","epoch 215, loss 0.4287134110927582\n","epoch 216, loss 0.4258531332015991\n","Parameter containing:\n","tensor([[0.9112, 1.9822, 0.8792],\n","        [1.7729, 1.9398, 0.7107],\n","        [0.6042, 1.3124, 0.7611],\n","        [0.8462, 1.8828, 0.9476]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2721, -0.0492,  0.5080,  0.0669], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9726, 5.6044, 3.6153, 4.3574]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4424], requires_grad=True)\n","epoch 217, loss 0.42302414774894714\n","epoch 218, loss 0.42022550106048584\n","epoch 219, loss 0.41745683550834656\n","epoch 220, loss 0.41471752524375916\n","epoch 221, loss 0.4120073616504669\n","Parameter containing:\n","tensor([[0.9080, 1.9853, 0.8881],\n","        [1.7750, 1.9457, 0.7154],\n","        [0.5931, 1.3105, 0.7750],\n","        [0.8430, 1.8852, 0.9542]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2674, -0.0557,  0.5072,  0.0646], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9759, 5.6079, 3.6186, 4.3610]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4476], requires_grad=True)\n","epoch 222, loss 0.40932613611221313\n","epoch 223, loss 0.4066726267337799\n","epoch 224, loss 0.4040467441082001\n","epoch 225, loss 0.4014483392238617\n","epoch 226, loss 0.39887675642967224\n","Parameter containing:\n","tensor([[0.9048, 1.9884, 0.8967],\n","        [1.7771, 1.9517, 0.7199],\n","        [0.5820, 1.3086, 0.7887],\n","        [0.8399, 1.8876, 0.9606]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2629, -0.0619,  0.5066,  0.0625], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9791, 5.6112, 3.6217, 4.3644]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4526], requires_grad=True)\n","epoch 227, loss 0.39633187651634216\n","epoch 228, loss 0.39381253719329834\n","epoch 229, loss 0.3913193345069885\n","epoch 230, loss 0.3888513147830963\n","epoch 231, loss 0.38640815019607544\n","Parameter containing:\n","tensor([[0.9018, 1.9916, 0.9049],\n","        [1.7792, 1.9575, 0.7242],\n","        [0.5709, 1.3067, 0.8020],\n","        [0.8369, 1.8902, 0.9667]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2586, -0.0679,  0.5064,  0.0606], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9821, 5.6143, 3.6247, 4.3676]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4573], requires_grad=True)\n","epoch 232, loss 0.3839893341064453\n","epoch 233, loss 0.3815951943397522\n","epoch 234, loss 0.37922459840774536\n","epoch 235, loss 0.37687787413597107\n","epoch 236, loss 0.3745543360710144\n","Parameter containing:\n","tensor([[0.8988, 1.9948, 0.9128],\n","        [1.7813, 1.9634, 0.7282],\n","        [0.5599, 1.3048, 0.8151],\n","        [0.8340, 1.8928, 0.9725]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2546, -0.0736,  0.5064,  0.0589], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9849, 5.6173, 3.6276, 4.3706]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4617], requires_grad=True)\n","epoch 237, loss 0.3722533881664276\n","epoch 238, loss 0.36997485160827637\n","epoch 239, loss 0.36771878600120544\n","epoch 240, loss 0.3654840886592865\n","epoch 241, loss 0.3632713556289673\n","Parameter containing:\n","tensor([[0.8960, 1.9980, 0.9205],\n","        [1.7834, 1.9693, 0.7320],\n","        [0.5488, 1.3030, 0.8279],\n","        [0.8312, 1.8955, 0.9780]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2508, -0.0792,  0.5067,  0.0574], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9876, 5.6201, 3.6303, 4.3735]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4659], requires_grad=True)\n","epoch 242, loss 0.3610799312591553\n","epoch 243, loss 0.3589099049568176\n","epoch 244, loss 0.3567603826522827\n","epoch 245, loss 0.3546306788921356\n","epoch 246, loss 0.3525213301181793\n","Parameter containing:\n","tensor([[0.8932, 2.0013, 0.9278],\n","        [1.7855, 1.9751, 0.7356],\n","        [0.5379, 1.3012, 0.8403],\n","        [0.8286, 1.8983, 0.9834]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2472, -0.0845,  0.5072,  0.0560], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9901, 5.6227, 3.6330, 4.3761]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4697], requires_grad=True)\n","epoch 247, loss 0.35043206810951233\n","epoch 248, loss 0.348361998796463\n","epoch 249, loss 0.3463113605976105\n","epoch 250, loss 0.3442799746990204\n","epoch 251, loss 0.34226682782173157\n","Parameter containing:\n","tensor([[0.8905, 2.0047, 0.9349],\n","        [1.7877, 1.9810, 0.7391],\n","        [0.5269, 1.2995, 0.8525],\n","        [0.8260, 1.9012, 0.9884]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2438, -0.0896,  0.5080,  0.0547], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9925, 5.6253, 3.6355, 4.3787]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4733], requires_grad=True)\n","epoch 252, loss 0.34027284383773804\n","epoch 253, loss 0.3382970988750458\n","epoch 254, loss 0.3363387882709503\n","epoch 255, loss 0.3343980312347412\n","epoch 256, loss 0.3324754536151886\n","Parameter containing:\n","tensor([[0.8880, 2.0082, 0.9417],\n","        [1.7899, 1.9868, 0.7423],\n","        [0.5161, 1.2979, 0.8645],\n","        [0.8235, 1.9042, 0.9933]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2406, -0.0946,  0.5090,  0.0536], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9948, 5.6277, 3.6379, 4.3811]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4767], requires_grad=True)\n","epoch 257, loss 0.3305695950984955\n","epoch 258, loss 0.32868146896362305\n","epoch 259, loss 0.32680949568748474\n","epoch 260, loss 0.3249543309211731\n","epoch 261, loss 0.3231154978275299\n","Parameter containing:\n","tensor([[0.8855, 2.0117, 0.9483],\n","        [1.7921, 1.9926, 0.7453],\n","        [0.5053, 1.2964, 0.8761],\n","        [0.8212, 1.9073, 0.9979]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2375, -0.0993,  0.5101,  0.0526], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9970, 5.6300, 3.6403, 4.3833]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4798], requires_grad=True)\n","epoch 262, loss 0.32129257917404175\n","epoch 263, loss 0.31948572397232056\n","epoch 264, loss 0.3176945447921753\n","epoch 265, loss 0.31591910123825073\n","epoch 266, loss 0.3141584098339081\n","Parameter containing:\n","tensor([[0.8832, 2.0153, 0.9546],\n","        [1.7943, 1.9985, 0.7482],\n","        [0.4946, 1.2949, 0.8875],\n","        [0.8189, 1.9106, 1.0023]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2346, -0.1039,  0.5115,  0.0517], requires_grad=True)\n","Parameter containing:\n","tensor([[4.9990, 5.6322, 3.6425, 4.3854]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4826], requires_grad=True)\n","epoch 267, loss 0.31241297721862793\n","epoch 268, loss 0.3106822967529297\n","epoch 269, loss 0.30896633863449097\n","epoch 270, loss 0.3072649836540222\n","epoch 271, loss 0.3055776357650757\n","Parameter containing:\n","tensor([[0.8810, 2.0190, 0.9607],\n","        [1.7965, 2.0043, 0.7510],\n","        [0.4840, 1.2936, 0.8986],\n","        [0.8168, 1.9139, 1.0065]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2318, -0.1084,  0.5130,  0.0510], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0010, 5.6344, 3.6446, 4.3875]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4852], requires_grad=True)\n","epoch 272, loss 0.3039044737815857\n","epoch 273, loss 0.30224496126174927\n","epoch 274, loss 0.3005998730659485\n","epoch 275, loss 0.29896754026412964\n","epoch 276, loss 0.29734861850738525\n","Parameter containing:\n","tensor([[0.8789, 2.0228, 0.9665],\n","        [1.7988, 2.0101, 0.7535],\n","        [0.4736, 1.2923, 0.9095],\n","        [0.8148, 1.9173, 1.0105]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2292, -0.1126,  0.5146,  0.0503], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0028, 5.6364, 3.6467, 4.3894]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4876], requires_grad=True)\n","epoch 277, loss 0.2957424819469452\n","epoch 278, loss 0.29414981603622437\n","epoch 279, loss 0.29256993532180786\n","epoch 280, loss 0.2910028100013733\n","epoch 281, loss 0.2894476652145386\n","Parameter containing:\n","tensor([[0.8769, 2.0266, 0.9721],\n","        [1.8011, 2.0159, 0.7559],\n","        [0.4632, 1.2912, 0.9201],\n","        [0.8129, 1.9209, 1.0143]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2267, -0.1168,  0.5165,  0.0497], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0046, 5.6384, 3.6486, 4.3912]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4897], requires_grad=True)\n","epoch 282, loss 0.2879045009613037\n","epoch 283, loss 0.2863748073577881\n","epoch 284, loss 0.2848562002182007\n","epoch 285, loss 0.28334903717041016\n","epoch 286, loss 0.28185388445854187\n","Parameter containing:\n","tensor([[0.8750, 2.0305, 0.9775],\n","        [1.8034, 2.0217, 0.7582],\n","        [0.4529, 1.2902, 0.9304],\n","        [0.8111, 1.9245, 1.0179]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2243, -0.1208,  0.5184,  0.0492], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0062, 5.6402, 3.6505, 4.3928]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4917], requires_grad=True)\n","epoch 287, loss 0.2803703248500824\n","epoch 288, loss 0.27889832854270935\n","epoch 289, loss 0.2774372398853302\n","epoch 290, loss 0.27598708868026733\n","epoch 291, loss 0.27454790472984314\n","Parameter containing:\n","tensor([[0.8732, 2.0345, 0.9827],\n","        [1.8057, 2.0275, 0.7604],\n","        [0.4427, 1.2893, 0.9406],\n","        [0.8094, 1.9282, 1.0213]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2220, -0.1246,  0.5205,  0.0488], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0078, 5.6420, 3.6523, 4.3944]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4934], requires_grad=True)\n","epoch 292, loss 0.27311959862709045\n","epoch 293, loss 0.2717020809650421\n","epoch 294, loss 0.27029481530189514\n","epoch 295, loss 0.2688983976840973\n","epoch 296, loss 0.2675113081932068\n","Parameter containing:\n","tensor([[0.8715, 2.0386, 0.9876],\n","        [1.8080, 2.0333, 0.7624],\n","        [0.4327, 1.2885, 0.9504],\n","        [0.8079, 1.9320, 1.0246]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2199, -0.1284,  0.5227,  0.0485], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0093, 5.6437, 3.6540, 4.3960]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4949], requires_grad=True)\n","epoch 297, loss 0.2661345601081848\n","epoch 298, loss 0.2647680938243866\n","epoch 299, loss 0.2634114623069763\n","epoch 300, loss 0.26206478476524353\n","epoch 301, loss 0.2607274353504181\n","Parameter containing:\n","tensor([[0.8700, 2.0427, 0.9924],\n","        [1.8103, 2.0391, 0.7643],\n","        [0.4228, 1.2878, 0.9601],\n","        [0.8064, 1.9359, 1.0277]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2178, -0.1320,  0.5250,  0.0482], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0107, 5.6454, 3.6557, 4.3974]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4962], requires_grad=True)\n","epoch 302, loss 0.2593989670276642\n","epoch 303, loss 0.25808030366897583\n","epoch 304, loss 0.25677117705345154\n","epoch 305, loss 0.25547099113464355\n","epoch 306, loss 0.2541798949241638\n","Parameter containing:\n","tensor([[0.8685, 2.0468, 0.9970],\n","        [1.8126, 2.0448, 0.7660],\n","        [0.4130, 1.2872, 0.9696],\n","        [0.8050, 1.9398, 1.0306]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2159, -0.1354,  0.5274,  0.0480], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0121, 5.6470, 3.6573, 4.3987]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4973], requires_grad=True)\n","epoch 307, loss 0.2528974711894989\n","epoch 308, loss 0.2516236901283264\n","epoch 309, loss 0.2503593862056732\n","epoch 310, loss 0.24910320341587067\n","epoch 311, loss 0.24785558879375458\n","Parameter containing:\n","tensor([[0.8671, 2.0510, 1.0014],\n","        [1.8150, 2.0505, 0.7677],\n","        [0.4033, 1.2867, 0.9788],\n","        [0.8037, 1.9438, 1.0334]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2140, -0.1388,  0.5300,  0.0479], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0133, 5.6485, 3.6588, 4.4000]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4983], requires_grad=True)\n","epoch 312, loss 0.24661600589752197\n","epoch 313, loss 0.24538493156433105\n","epoch 314, loss 0.24416233599185944\n","epoch 315, loss 0.24294742941856384\n","epoch 316, loss 0.24174079298973083\n","Parameter containing:\n","tensor([[0.8658, 2.0553, 1.0057],\n","        [1.8173, 2.0562, 0.7693],\n","        [0.3937, 1.2863, 0.9878],\n","        [0.8025, 1.9479, 1.0361]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2123, -0.1421,  0.5326,  0.0478], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0145, 5.6500, 3.6602, 4.4012]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4990], requires_grad=True)\n","epoch 317, loss 0.24054157733917236\n","epoch 318, loss 0.2393505722284317\n","epoch 319, loss 0.23816700279712677\n","epoch 320, loss 0.23699147999286652\n","epoch 321, loss 0.23582303524017334\n","Parameter containing:\n","tensor([[0.8646, 2.0596, 1.0097],\n","        [1.8196, 2.0618, 0.7708],\n","        [0.3843, 1.2860, 0.9966],\n","        [0.8014, 1.9520, 1.0386]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2106, -0.1452,  0.5352,  0.0478], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0157, 5.6514, 3.6616, 4.4023]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4996], requires_grad=True)\n","epoch 322, loss 0.23466235399246216\n","epoch 323, loss 0.23350898921489716\n","epoch 324, loss 0.23236332833766937\n","epoch 325, loss 0.23122423887252808\n","epoch 326, loss 0.2300925850868225\n","Parameter containing:\n","tensor([[0.8635, 2.0640, 1.0137],\n","        [1.8220, 2.0675, 0.7721],\n","        [0.3750, 1.2858, 1.0053],\n","        [0.8003, 1.9561, 1.0410]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2090, -0.1483,  0.5380,  0.0478], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0168, 5.6527, 3.6629, 4.4033]], requires_grad=True)\n","Parameter containing:\n","tensor([6.5001], requires_grad=True)\n","epoch 327, loss 0.2289680540561676\n","epoch 328, loss 0.22785042226314545\n","epoch 329, loss 0.2267397791147232\n","epoch 330, loss 0.22563573718070984\n","epoch 331, loss 0.22453902661800385\n","Parameter containing:\n","tensor([[0.8624, 2.0683, 1.0174],\n","        [1.8243, 2.0730, 0.7734],\n","        [0.3658, 1.2858, 1.0137],\n","        [0.7994, 1.9603, 1.0433]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2074, -0.1513,  0.5408,  0.0478], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0178, 5.6540, 3.6642, 4.4043]], requires_grad=True)\n","Parameter containing:\n","tensor([6.5004], requires_grad=True)\n","epoch 332, loss 0.2234480381011963\n","epoch 333, loss 0.22236447036266327\n","epoch 334, loss 0.2212875932455063\n","epoch 335, loss 0.2202165573835373\n","epoch 336, loss 0.21915248036384583\n","Parameter containing:\n","tensor([[0.8614, 2.0727, 1.0210],\n","        [1.8266, 2.0786, 0.7747],\n","        [0.3567, 1.2858, 1.0219],\n","        [0.7985, 1.9646, 1.0454]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2060, -0.1541,  0.5437,  0.0479], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0187, 5.6553, 3.6654, 4.4052]], requires_grad=True)\n","Parameter containing:\n","tensor([6.5006], requires_grad=True)\n","epoch 337, loss 0.21809454262256622\n","epoch 338, loss 0.21704283356666565\n","epoch 339, loss 0.21599693596363068\n","epoch 340, loss 0.21495765447616577\n","epoch 341, loss 0.21392446756362915\n","Parameter containing:\n","tensor([[0.8606, 2.0772, 1.0245],\n","        [1.8289, 2.0841, 0.7758],\n","        [0.3478, 1.2858, 1.0300],\n","        [0.7977, 1.9688, 1.0475]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2046, -0.1569,  0.5467,  0.0481], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0197, 5.6565, 3.6665, 4.4061]], requires_grad=True)\n","Parameter containing:\n","tensor([6.5006], requires_grad=True)\n","epoch 342, loss 0.2128974348306656\n","epoch 343, loss 0.21187594532966614\n","epoch 344, loss 0.21086092293262482\n","epoch 345, loss 0.20985203981399536\n","epoch 346, loss 0.20884811878204346\n","Parameter containing:\n","tensor([[0.8597, 2.0816, 1.0279],\n","        [1.8313, 2.0896, 0.7768],\n","        [0.3390, 1.2860, 1.0379],\n","        [0.7969, 1.9731, 1.0494]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2033, -0.1596,  0.5497,  0.0482], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0205, 5.6577, 3.6676, 4.4068]], requires_grad=True)\n","Parameter containing:\n","tensor([6.5005], requires_grad=True)\n","epoch 347, loss 0.2078504115343094\n","epoch 348, loss 0.20685841143131256\n","epoch 349, loss 0.2058720737695694\n","epoch 350, loss 0.20489132404327393\n","epoch 351, loss 0.2039160132408142\n","Parameter containing:\n","tensor([[0.8590, 2.0861, 1.0311],\n","        [1.8336, 2.0950, 0.7778],\n","        [0.3303, 1.2863, 1.0456],\n","        [0.7963, 1.9775, 1.0512]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2020, -0.1622,  0.5527,  0.0484], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0213, 5.6588, 3.6687, 4.4076]], requires_grad=True)\n","Parameter containing:\n","tensor([6.5003], requires_grad=True)\n","epoch 352, loss 0.20294588804244995\n","epoch 353, loss 0.20198170840740204\n","epoch 354, loss 0.20102302730083466\n","epoch 355, loss 0.20006975531578064\n","epoch 356, loss 0.19912107288837433\n","Parameter containing:\n","tensor([[0.8583, 2.0905, 1.0342],\n","        [1.8359, 2.1004, 0.7788],\n","        [0.3217, 1.2866, 1.0531],\n","        [0.7957, 1.9818, 1.0530]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2008, -0.1648,  0.5558,  0.0486], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0221, 5.6598, 3.6697, 4.4083]], requires_grad=True)\n","Parameter containing:\n","tensor([6.5000], requires_grad=True)\n","epoch 357, loss 0.1981782764196396\n","epoch 358, loss 0.1972402036190033\n","epoch 359, loss 0.19630767405033112\n","epoch 360, loss 0.19538049399852753\n","epoch 361, loss 0.19445814192295074\n","Parameter containing:\n","tensor([[0.8577, 2.0950, 1.0371],\n","        [1.8381, 2.1057, 0.7796],\n","        [0.3132, 1.2870, 1.0605],\n","        [0.7951, 1.9862, 1.0546]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1996, -0.1673,  0.5590,  0.0489], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0228, 5.6609, 3.6706, 4.4089]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4995], requires_grad=True)\n","epoch 362, loss 0.19354063272476196\n","epoch 363, loss 0.19262833893299103\n","epoch 364, loss 0.19172100722789764\n","epoch 365, loss 0.19081899523735046\n","epoch 366, loss 0.18992094695568085\n","Parameter containing:\n","tensor([[0.8571, 2.0995, 1.0400],\n","        [1.8404, 2.1110, 0.7804],\n","        [0.3049, 1.2875, 1.0677],\n","        [0.7946, 1.9905, 1.0562]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1985, -0.1696,  0.5621,  0.0492], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0235, 5.6618, 3.6715, 4.4095]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4990], requires_grad=True)\n","epoch 367, loss 0.18902842700481415\n","epoch 368, loss 0.18814027309417725\n","epoch 369, loss 0.18725746870040894\n","epoch 370, loss 0.18637911975383759\n","epoch 371, loss 0.18550503253936768\n","Parameter containing:\n","tensor([[0.8566, 2.1040, 1.0427],\n","        [1.8427, 2.1163, 0.7812],\n","        [0.2967, 1.2880, 1.0748],\n","        [0.7942, 1.9949, 1.0577]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1975, -0.1720,  0.5653,  0.0494], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0241, 5.6628, 3.6724, 4.4101]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4984], requires_grad=True)\n","epoch 372, loss 0.18463625013828278\n","epoch 373, loss 0.18377166986465454\n","epoch 374, loss 0.18291179835796356\n","epoch 375, loss 0.18205653131008148\n","epoch 376, loss 0.1812058836221695\n","Parameter containing:\n","tensor([[0.8561, 2.1085, 1.0454],\n","        [1.8449, 2.1214, 0.7819],\n","        [0.2886, 1.2886, 1.0817],\n","        [0.7938, 1.9993, 1.0591]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1965, -0.1742,  0.5685,  0.0497], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0247, 5.6637, 3.6732, 4.4106]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4977], requires_grad=True)\n","epoch 377, loss 0.18035957217216492\n","epoch 378, loss 0.17951758205890656\n","epoch 379, loss 0.17868053913116455\n","epoch 380, loss 0.17784744501113892\n","epoch 381, loss 0.1770181953907013\n","Parameter containing:\n","tensor([[0.8557, 2.1130, 1.0479],\n","        [1.8472, 2.1266, 0.7825],\n","        [0.2806, 1.2893, 1.0885],\n","        [0.7934, 2.0036, 1.0604]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1955, -0.1764,  0.5718,  0.0501], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0252, 5.6646, 3.6740, 4.4110]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4969], requires_grad=True)\n","epoch 382, loss 0.17619410157203674\n","epoch 383, loss 0.17537418007850647\n","epoch 384, loss 0.17455890774726868\n","epoch 385, loss 0.17374704778194427\n","epoch 386, loss 0.17293956875801086\n","Parameter containing:\n","tensor([[0.8554, 2.1174, 1.0504],\n","        [1.8494, 2.1317, 0.7831],\n","        [0.2727, 1.2900, 1.0951],\n","        [0.7931, 2.0080, 1.0617]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1946, -0.1786,  0.5751,  0.0504], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0257, 5.6654, 3.6747, 4.4115]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4960], requires_grad=True)\n","epoch 387, loss 0.172136589884758\n","epoch 388, loss 0.17133721709251404\n","epoch 389, loss 0.17054224014282227\n","epoch 390, loss 0.16975146532058716\n","epoch 391, loss 0.16896480321884155\n","Parameter containing:\n","tensor([[0.8550, 2.1219, 1.0528],\n","        [1.8516, 2.1367, 0.7837],\n","        [0.2650, 1.2908, 1.1016],\n","        [0.7929, 2.0124, 1.0629]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1938, -0.1806,  0.5784,  0.0508], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0262, 5.6662, 3.6754, 4.4119]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4951], requires_grad=True)\n","epoch 392, loss 0.16818201541900635\n","epoch 393, loss 0.16740331053733826\n","epoch 394, loss 0.1666286140680313\n","epoch 395, loss 0.16585813462734222\n","epoch 396, loss 0.1650908887386322\n","Parameter containing:\n","tensor([[0.8548, 2.1263, 1.0550],\n","        [1.8537, 2.1417, 0.7842],\n","        [0.2573, 1.2916, 1.1080],\n","        [0.7927, 2.0167, 1.0640]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1929, -0.1826,  0.5817,  0.0511], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0267, 5.6670, 3.6761, 4.4122]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4941], requires_grad=True)\n","epoch 397, loss 0.1643282175064087\n","epoch 398, loss 0.1635691374540329\n","epoch 399, loss 0.16281378269195557\n","epoch 400, loss 0.16206246614456177\n","epoch 401, loss 0.16131506860256195\n","Parameter containing:\n","tensor([[0.8545, 2.1308, 1.0572],\n","        [1.8559, 2.1466, 0.7847],\n","        [0.2498, 1.2925, 1.1142],\n","        [0.7925, 2.0210, 1.0651]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1921, -0.1846,  0.5850,  0.0515], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0271, 5.6678, 3.6768, 4.4126]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4930], requires_grad=True)\n","epoch 402, loss 0.1605713665485382\n","epoch 403, loss 0.1598314344882965\n","epoch 404, loss 0.15909530222415924\n","epoch 405, loss 0.15836265683174133\n","epoch 406, loss 0.1576341688632965\n","Parameter containing:\n","tensor([[0.8543, 2.1352, 1.0593],\n","        [1.8580, 2.1515, 0.7851],\n","        [0.2424, 1.2935, 1.1203],\n","        [0.7923, 2.0254, 1.0661]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1914, -0.1865,  0.5883,  0.0519], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0275, 5.6685, 3.6774, 4.4129]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4919], requires_grad=True)\n","epoch 407, loss 0.15690889954566956\n","epoch 408, loss 0.1561872363090515\n","epoch 409, loss 0.15546956658363342\n","epoch 410, loss 0.15475527942180634\n","epoch 411, loss 0.15404438972473145\n","Parameter containing:\n","tensor([[0.8542, 2.1396, 1.0614],\n","        [1.8601, 2.1563, 0.7855],\n","        [0.2351, 1.2944, 1.1263],\n","        [0.7922, 2.0297, 1.0671]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1907, -0.1884,  0.5916,  0.0523], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0278, 5.6692, 3.6780, 4.4131]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4907], requires_grad=True)\n","epoch 412, loss 0.1533375233411789\n","epoch 413, loss 0.15263386070728302\n","epoch 414, loss 0.15193387866020203\n","epoch 415, loss 0.15123768150806427\n","epoch 416, loss 0.15054458379745483\n","Parameter containing:\n","tensor([[0.8540, 2.1440, 1.0633],\n","        [1.8622, 2.1611, 0.7859],\n","        [0.2278, 1.2955, 1.1322],\n","        [0.7922, 2.0339, 1.0680]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1900, -0.1902,  0.5949,  0.0527], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0282, 5.6698, 3.6786, 4.4134]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4895], requires_grad=True)\n","epoch 417, loss 0.1498548537492752\n","epoch 418, loss 0.14916881918907166\n","epoch 419, loss 0.14848604798316956\n","epoch 420, loss 0.1478065401315689\n","epoch 421, loss 0.14713115990161896\n","Parameter containing:\n","tensor([[0.8539, 2.1483, 1.0652],\n","        [1.8643, 2.1658, 0.7863],\n","        [0.2207, 1.2965, 1.1379],\n","        [0.7921, 2.0382, 1.0689]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1893, -0.1919,  0.5983,  0.0531], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0285, 5.6705, 3.6791, 4.4136]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4882], requires_grad=True)\n","epoch 422, loss 0.14645832777023315\n","epoch 423, loss 0.1457889974117279\n","epoch 424, loss 0.14512325823307037\n","epoch 425, loss 0.14446069300174713\n","epoch 426, loss 0.1438017189502716\n","Parameter containing:\n","tensor([[0.8539, 2.1526, 1.0671],\n","        [1.8664, 2.1704, 0.7866],\n","        [0.2137, 1.2976, 1.1436],\n","        [0.7921, 2.0424, 1.0698]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1887, -0.1936,  0.6016,  0.0535], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0288, 5.6711, 3.6796, 4.4138]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4869], requires_grad=True)\n","epoch 427, loss 0.14314571022987366\n","epoch 428, loss 0.14249305427074432\n","epoch 429, loss 0.1418433040380478\n","epoch 430, loss 0.14119720458984375\n","epoch 431, loss 0.14055459201335907\n","Parameter containing:\n","tensor([[0.8539, 2.1569, 1.0688],\n","        [1.8684, 2.1750, 0.7869],\n","        [0.2068, 1.2988, 1.1491],\n","        [0.7921, 2.0467, 1.0705]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1881, -0.1953,  0.6049,  0.0540], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0290, 5.6717, 3.6801, 4.4139]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4855], requires_grad=True)\n","epoch 432, loss 0.13991448283195496\n","epoch 433, loss 0.13927774131298065\n","epoch 434, loss 0.13864421844482422\n","epoch 435, loss 0.13801397383213043\n","epoch 436, loss 0.13738639652729034\n","Parameter containing:\n","tensor([[0.8538, 2.1612, 1.0705],\n","        [1.8704, 2.1795, 0.7871],\n","        [0.2000, 1.2999, 1.1545],\n","        [0.7922, 2.0508, 1.0713]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1875, -0.1969,  0.6083,  0.0544], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0293, 5.6723, 3.6806, 4.4141]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4841], requires_grad=True)\n","epoch 437, loss 0.13676249980926514\n","epoch 438, loss 0.13614152371883392\n","epoch 439, loss 0.13552382588386536\n","epoch 440, loss 0.13490846753120422\n","epoch 441, loss 0.134296715259552\n","Parameter containing:\n","tensor([[0.8539, 2.1654, 1.0722],\n","        [1.8724, 2.1840, 0.7874],\n","        [0.1933, 1.3012, 1.1599],\n","        [0.7922, 2.0550, 1.0720]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1870, -0.1985,  0.6116,  0.0548], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0295, 5.6728, 3.6810, 4.4142]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4827], requires_grad=True)\n","epoch 442, loss 0.13368792831897736\n","epoch 443, loss 0.13308186829090118\n","epoch 444, loss 0.1324792057275772\n","epoch 445, loss 0.13187912106513977\n","epoch 446, loss 0.1312820464372635\n","Parameter containing:\n","tensor([[0.8539, 2.1696, 1.0738],\n","        [1.8744, 2.1884, 0.7876],\n","        [0.1867, 1.3024, 1.1651],\n","        [0.7923, 2.0591, 1.0727]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1864, -0.2000,  0.6149,  0.0553], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0297, 5.6734, 3.6815, 4.4143]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4813], requires_grad=True)\n","epoch 447, loss 0.13068819046020508\n","epoch 448, loss 0.1300971806049347\n","epoch 449, loss 0.12950918078422546\n","epoch 450, loss 0.12892407178878784\n","epoch 451, loss 0.12834171950817108\n","Parameter containing:\n","tensor([[0.8540, 2.1738, 1.0753],\n","        [1.8763, 2.1928, 0.7878],\n","        [0.1802, 1.3036, 1.1702],\n","        [0.7924, 2.0632, 1.0733]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1859, -0.2015,  0.6182,  0.0557], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0299, 5.6739, 3.6819, 4.4144]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4798], requires_grad=True)\n","epoch 452, loss 0.1277620643377304\n","epoch 453, loss 0.12718574702739716\n","epoch 454, loss 0.126611590385437\n","epoch 455, loss 0.12604059278964996\n","epoch 456, loss 0.12547263503074646\n","Parameter containing:\n","tensor([[0.8540, 2.1779, 1.0768],\n","        [1.8783, 2.1971, 0.7880],\n","        [0.1738, 1.3049, 1.1753],\n","        [0.7925, 2.0673, 1.0739]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1855, -0.2030,  0.6215,  0.0561], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0300, 5.6744, 3.6823, 4.4144]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4783], requires_grad=True)\n","epoch 457, loss 0.12490755319595337\n","epoch 458, loss 0.12434478849172592\n","epoch 459, loss 0.12378529459238052\n","epoch 460, loss 0.12322784215211868\n","epoch 461, loss 0.12267368286848068\n","Parameter containing:\n","tensor([[0.8541, 2.1820, 1.0782],\n","        [1.8802, 2.2014, 0.7881],\n","        [0.1675, 1.3063, 1.1802],\n","        [0.7926, 2.0713, 1.0745]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1850, -0.2044,  0.6248,  0.0566], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0302, 5.6748, 3.6827, 4.4145]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4767], requires_grad=True)\n","epoch 462, loss 0.12212233990430832\n","epoch 463, loss 0.12157344073057175\n","epoch 464, loss 0.12102703005075455\n","epoch 465, loss 0.12048366665840149\n","epoch 466, loss 0.11994309723377228\n","Parameter containing:\n","tensor([[0.8543, 2.1861, 1.0796],\n","        [1.8821, 2.2056, 0.7883],\n","        [0.1613, 1.3076, 1.1850],\n","        [0.7928, 2.0753, 1.0751]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1846, -0.2058,  0.6281,  0.0570], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0303, 5.6753, 3.6831, 4.4145]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4752], requires_grad=True)\n","epoch 467, loss 0.1194051131606102\n","epoch 468, loss 0.1188696101307869\n","epoch 469, loss 0.1183370053768158\n","epoch 470, loss 0.11780647188425064\n","epoch 471, loss 0.11727873235940933\n","Parameter containing:\n","tensor([[0.8544, 2.1902, 1.0809],\n","        [1.8839, 2.2098, 0.7884],\n","        [0.1551, 1.3089, 1.1898],\n","        [0.7930, 2.0793, 1.0756]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1842, -0.2072,  0.6314,  0.0575], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0304, 5.6757, 3.6834, 4.4145]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4736], requires_grad=True)\n","epoch 472, loss 0.11675387620925903\n","epoch 473, loss 0.11623164266347885\n","epoch 474, loss 0.11571180075407028\n","epoch 475, loss 0.11519456654787064\n","epoch 476, loss 0.11467987298965454\n","Parameter containing:\n","tensor([[0.8546, 2.1942, 1.0822],\n","        [1.8858, 2.2138, 0.7885],\n","        [0.1491, 1.3103, 1.1945],\n","        [0.7932, 2.0832, 1.0761]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1838, -0.2085,  0.6346,  0.0579], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0305, 5.6762, 3.6838, 4.4146]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4721], requires_grad=True)\n","epoch 477, loss 0.11416786164045334\n","epoch 478, loss 0.11365785449743271\n","epoch 479, loss 0.11315081268548965\n","epoch 480, loss 0.11264605075120926\n","epoch 481, loss 0.11214389652013779\n","Parameter containing:\n","tensor([[0.8547, 2.1981, 1.0835],\n","        [1.8876, 2.2179, 0.7886],\n","        [0.1431, 1.3117, 1.1991],\n","        [0.7934, 2.0871, 1.0766]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1834, -0.2098,  0.6379,  0.0584], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0306, 5.6766, 3.6841, 4.4145]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4705], requires_grad=True)\n","epoch 482, loss 0.11164437234401703\n","epoch 483, loss 0.11114691197872162\n","epoch 484, loss 0.11065225303173065\n","epoch 485, loss 0.11016010493040085\n","epoch 486, loss 0.10966971516609192\n","Parameter containing:\n","tensor([[0.8549, 2.2020, 1.0847],\n","        [1.8894, 2.2219, 0.7887],\n","        [0.1372, 1.3131, 1.2036],\n","        [0.7936, 2.0910, 1.0770]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1831, -0.2110,  0.6411,  0.0588], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0307, 5.6770, 3.6844, 4.4145]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4689], requires_grad=True)\n","epoch 487, loss 0.10918234288692474\n","epoch 488, loss 0.10869711637496948\n","epoch 489, loss 0.10821417719125748\n","epoch 490, loss 0.10773422569036484\n","epoch 491, loss 0.1072562113404274\n","Parameter containing:\n","tensor([[0.8551, 2.2059, 1.0858],\n","        [1.8911, 2.2258, 0.7887],\n","        [0.1315, 1.3146, 1.2080],\n","        [0.7938, 2.0948, 1.0774]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1828, -0.2123,  0.6443,  0.0593], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0308, 5.6773, 3.6848, 4.4145]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4672], requires_grad=True)\n","epoch 492, loss 0.10678043216466904\n","epoch 493, loss 0.10630671679973602\n","epoch 494, loss 0.10583581030368805\n","epoch 495, loss 0.10536759346723557\n","epoch 496, loss 0.10490112006664276\n","Parameter containing:\n","tensor([[0.8553, 2.2098, 1.0870],\n","        [1.8929, 2.2297, 0.7888],\n","        [0.1258, 1.3160, 1.2124],\n","        [0.7940, 2.0986, 1.0778]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1824, -0.2135,  0.6475,  0.0597], requires_grad=True)\n","Parameter containing:\n","tensor([[5.0308, 5.6777, 3.6851, 4.4144]], requires_grad=True)\n","Parameter containing:\n","tensor([6.4656], requires_grad=True)\n","epoch 497, loss 0.10443668812513351\n","epoch 498, loss 0.10397512465715408\n","epoch 499, loss 0.10351543128490448\n","epoch 500, loss 0.10305815190076828\n"],"name":"stdout"}]},{"metadata":{"id":"52f3CdEHT4Y8","colab_type":"text"},"cell_type":"markdown","source":["###Plotting the Loss vs Epochs graph"]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-15T15:21:26.445260Z","start_time":"2018-10-15T15:21:26.282006Z"},"id":"hu6RrNJsmQE6","colab_type":"code","outputId":"9d20987d-ffe3-4c3a-e6bd-4de1a8e4df08","executionInfo":{"status":"ok","timestamp":1548762651316,"user_tz":-330,"elapsed":8747,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":376}},"cell_type":"code","source":["#Plotting Loss vs Epochs\n","fig,ax = plt.subplots(1)\n","plt.title('Loss vs Epochs')\n","ax.plot(losses)\n","ax.set_ylabel('Loss')\n","ax.set_xlabel('Epoch')\n","plt.savefig('Loss_vs_Epoch.png')"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfIAAAFnCAYAAABdOssgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}