{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP_Regression.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"lBPJEbHmmlS_","colab_type":"text"},"cell_type":"markdown","source":["# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"uJSPjgtDcVBa","colab_type":"text"},"cell_type":"markdown","source":["###Not for Grading"]},{"metadata":{"id":"giKRyJXKmpqL","colab_type":"text"},"cell_type":"markdown","source":["\n","####Regression using MLP with MSE Loss"]},{"metadata":{"id":"3iXTrneDmzN_","colab_type":"text"},"cell_type":"markdown","source":["The objective of this case study is to understand regression i.e., to predict the price of the house using Multilayer perceptron with Cross Entropy Loss.  The package used here is  [PyTorch](https://pytorch.org/). "]},{"metadata":{"id":"jdkRVbGhS26c","colab_type":"text"},"cell_type":"markdown","source":["##*We will see more on PyTorch in the upcoming sessions.*"]},{"metadata":{"id":"v1BKwE3rWi7j","colab_type":"text"},"cell_type":"markdown","source":["#### Setup Steps"]},{"metadata":{"id":"wsULhbIZWh3I","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P18_test\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IziqgHiFWg0B","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"912345678\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xlT9zYI8RpbT","colab_type":"code","cellView":"form","outputId":"5a8ea69f-6ffe-4f49-d8bb-a6eb513b566a","executionInfo":{"status":"ok","timestamp":1553407099860,"user_tz":-330,"elapsed":1355,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","  \n","notebook=\"M1W2_CS_6_MLP_Regression\" #name of the notebook\n","Answer = \"Ungraded\"\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")  \n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      print(\"Your submission is successful.\")\n","      print(\"Ref Id:\", submission_id)\n","      print(\"Date of submission: \", r[\"date\"])\n","      print(\"Time of submission: \", r[\"time\"])\n","      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n","      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","    from IPython.display import HTML\n","    HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id))\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=P18_test&recordId=21356\"></script>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"rsciwGvITU-R","colab_type":"text"},"cell_type":"markdown","source":["### Importing required packages "]},{"metadata":{"id":"T2vxSk8VpJ0L","colab_type":"code","colab":{}},"cell_type":"code","source":["# Importing required Packages\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import  torch\n","from torch import nn\n","from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5ncXRJfzTYsL","colab_type":"text"},"cell_type":"markdown","source":["###The attributes of related House price are stored in \"X\" as features and the prices of the houses are stored in \"y\" as labels"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:34:08.691158Z","start_time":"2018-11-23T07:34:08.685467Z"},"id":"KhJrSQ0wmQDN","colab_type":"code","colab":{}},"cell_type":"code","source":["X = np.array([[3, 2000, 90], [2, 800, 143], [2, 850, 167], [1, 550, 267], [4, 2000, 396]])\n","y =  np.array([23.0, 8, 9.0, 9.0 , 25.0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ppxbl6p_Tj80","colab_type":"text"},"cell_type":"markdown","source":["###Standard scaling the features \"X\""]},{"metadata":{"id":"rUBlUjsLpxQC","colab_type":"code","outputId":"60dc9e32-7bb7-4f69-b41c-a746b23556de","executionInfo":{"status":"ok","timestamp":1553407100940,"user_tz":-330,"elapsed":795,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":176}},"cell_type":"code","source":["\n","ss = StandardScaler()\n","ss.fit(X)\n","X = ss.transform(X)\n","X"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n","  warnings.warn(msg, DataConversionWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n","  warnings.warn(msg, DataConversionWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([[ 0.58834841,  1.20863526, -1.13296108],\n","       [-0.39223227, -0.6997362 , -0.64318182],\n","       [-0.39223227, -0.62022073, -0.42139498],\n","       [-1.37281295, -1.09731359,  0.50271682],\n","       [ 1.56892908,  1.20863526,  1.69482106]])"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"BzA2wSs-Tne5","colab_type":"text"},"cell_type":"markdown","source":["###Defining the model for Linear Regression with MLP using PyTorch's nn.Module"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:32:33.885729Z","start_time":"2018-11-23T07:32:33.875066Z"},"id":"4NTCCccwmQEp","colab_type":"code","colab":{}},"cell_type":"code","source":["class LinearRegressionModel(nn.Module):\n","\n","    def __init__(self, input_dim, output_dim):\n","\n","        super(LinearRegressionModel, self).__init__() \n","        # Calling Super Class's constructor\n","        self.linear1 = nn.Linear(input_dim, 4)\n","        self.sigmoid = nn.Sigmoid()\n","        self.linear2 = nn.Linear(4, output_dim)\n","        # nn.Linear is defined in nn.Module\n","\n","    def forward(self, x):\n","        # Here the forward pass is simply a linear function\n","        #print(x.size())\n","        out = self.sigmoid(self.linear1(x))\n","        out = self.linear2(out)\n","        return out\n","\n","input_dim = 3\n","output_dim = 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AvshRKhrTuIV","colab_type":"text"},"cell_type":"markdown","source":["###The LinearRegressionModel() is saved in model below"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:33:14.943117Z","start_time":"2018-11-23T07:33:14.931903Z"},"id":"wQa8qRHemQEv","colab_type":"code","colab":{}},"cell_type":"code","source":["model = LinearRegressionModel(input_dim,output_dim)\n","criterion = nn.MSELoss()# Mean Squared Loss\n","l_rate = 0.01 #Learning Rate\n","optimiser = torch.optim.SGD(model.parameters(), lr = l_rate) #Stochastic Gradient Descent\n","\n","epochs = 500 #number of epochs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"to9oEE8yT1vb","colab_type":"text"},"cell_type":"markdown","source":["###Storing the losses in a list for the prescribed epochs"]},{"metadata":{"ExecuteTime":{"end_time":"2018-11-23T07:37:06.946827Z","start_time":"2018-11-23T07:37:06.921324Z"},"scrolled":false,"id":"Tm7a9HyXmQE1","colab_type":"code","outputId":"2d9ada79-8250-4232-e283-d098a50d2d8d","executionInfo":{"status":"ok","timestamp":1553407103583,"user_tz":-330,"elapsed":1374,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":28461}},"cell_type":"code","source":["losses = []\n","for epoch in range(epochs):\n","#increase the number of epochs by 1 every time\n","    epoch +=1\n","    inputs = torch.from_numpy(X.astype(np.float32))\n","    labels = torch.from_numpy(y.astype(np.float32))\n","    #clear grads as discussed in prev post\n","    optimiser.zero_grad()\n","    #forward to get predicted values\n","    outputs = model.forward(inputs)\n","    #print('outputs: ', outputs.size())\n","    #print('labels: ', labels.size())\n","    loss = criterion(outputs, labels.unsqueeze(1))\n","    loss.backward()# back props\n","    optimiser.step()# update the parameters\n","    print('epoch {}, loss {}'.format(epoch,loss.item()))\n","    losses.append(loss.item())\n","    if (epoch-1)%5 == 0:\n","        for i in model.parameters():\n","            print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch 1, loss 276.5071105957031\n","Parameter containing:\n","tensor([[ 0.2604, -0.4120,  0.2004],\n","        [-0.5753,  0.4235, -0.0850],\n","        [ 0.2543,  0.3148,  0.5325],\n","        [ 0.3425,  0.3019,  0.3521]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.1600, -0.1275, -0.0971,  0.0216], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.2998,  0.1493,  0.2448, -0.2111]], requires_grad=True)\n","Parameter containing:\n","tensor([0.3744], requires_grad=True)\n","epoch 2, loss 258.28173828125\n","epoch 3, loss 241.39697265625\n","epoch 4, loss 225.57737731933594\n","epoch 5, loss 210.61685180664062\n","epoch 6, loss 196.36634826660156\n","Parameter containing:\n","tensor([[ 0.3492, -0.3122,  0.2252],\n","        [-0.5145,  0.4916, -0.0674],\n","        [ 0.3019,  0.3826,  0.5150],\n","        [ 0.3529,  0.3157,  0.3502]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.3401, -0.0048,  0.0429,  0.0464], requires_grad=True)\n","Parameter containing:\n","tensor([[1.0106, 0.7562, 0.9821, 0.5520]], requires_grad=True)\n","Parameter containing:\n","tensor([1.6791], requires_grad=True)\n","epoch 7, loss 182.72544860839844\n","epoch 8, loss 169.6356658935547\n","epoch 9, loss 157.0743865966797\n","epoch 10, loss 145.04818725585938\n","epoch 11, loss 133.58596801757812\n","Parameter containing:\n","tensor([[ 0.4927, -0.1348,  0.2315],\n","        [-0.3664,  0.6524, -0.0110],\n","        [ 0.3874,  0.5136,  0.4620],\n","        [ 0.4221,  0.4109,  0.3302]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6265, 0.2379, 0.2815, 0.2099], requires_grad=True)\n","Parameter containing:\n","tensor([[1.6627, 1.3133, 1.6381, 1.2020]], requires_grad=True)\n","Parameter containing:\n","tensor([2.7124], requires_grad=True)\n","epoch 12, loss 122.7304916381836\n","epoch 13, loss 112.52870178222656\n","epoch 14, loss 103.02188110351562\n","epoch 15, loss 94.23713684082031\n","epoch 16, loss 86.18293762207031\n","Parameter containing:\n","tensor([[ 0.6219,  0.0448,  0.2019],\n","        [-0.1941,  0.8403,  0.0595],\n","        [ 0.4759,  0.6578,  0.3934],\n","        [ 0.5100,  0.5384,  0.2944]], requires_grad=True)\n","Parameter containing:\n","tensor([0.8893, 0.4875, 0.5096, 0.3976], requires_grad=True)\n","Parameter containing:\n","tensor([[2.2364, 1.8324, 2.2057, 1.7546]], requires_grad=True)\n","Parameter containing:\n","tensor([3.4918], requires_grad=True)\n","epoch 17, loss 78.84848022460938\n","epoch 18, loss 72.20645904541016\n","epoch 19, loss 66.21721649169922\n","epoch 20, loss 60.83311462402344\n","epoch 21, loss 56.00231170654297\n","Parameter containing:\n","tensor([[ 0.7237,  0.1971,  0.1729],\n","        [-0.0579,  0.9988,  0.1090],\n","        [ 0.5565,  0.7907,  0.3429],\n","        [ 0.5949,  0.6662,  0.2625]], requires_grad=True)\n","Parameter containing:\n","tensor([1.0672, 0.6619, 0.6670, 0.5406], requires_grad=True)\n","Parameter containing:\n","tensor([[2.7006, 2.2762, 2.6694, 2.2056]], requires_grad=True)\n","Parameter containing:\n","tensor([4.0542], requires_grad=True)\n","epoch 22, loss 51.67181396484375\n","epoch 23, loss 47.789649963378906\n","epoch 24, loss 44.30634307861328\n","epoch 25, loss 41.175899505615234\n","epoch 26, loss 38.356292724609375\n","Parameter containing:\n","tensor([[0.8093, 0.3294, 0.1619],\n","        [0.0473, 1.1317, 0.1463],\n","        [0.6318, 0.9143, 0.3196],\n","        [0.6737, 0.7870, 0.2469]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1617, 0.7559, 0.7482, 0.6224], requires_grad=True)\n","Parameter containing:\n","tensor([[3.0600, 2.6332, 3.0370, 2.5650]], requires_grad=True)\n","Parameter containing:\n","tensor([4.4528], requires_grad=True)\n","epoch 27, loss 35.8096923828125\n","epoch 28, loss 33.50243377685547\n","epoch 29, loss 31.404888153076172\n","epoch 30, loss 29.491134643554688\n","epoch 31, loss 27.738685607910156\n","Parameter containing:\n","tensor([[0.8849, 0.4500, 0.1688],\n","        [0.1339, 1.2502, 0.1822],\n","        [0.7029, 1.0316, 0.3189],\n","        [0.7461, 0.9008, 0.2475]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1943, 0.7906, 0.7717, 0.6537], requires_grad=True)\n","Parameter containing:\n","tensor([[3.3381, 2.9186, 3.3297, 2.8525]], requires_grad=True)\n","Parameter containing:\n","tensor([4.7377], requires_grad=True)\n","epoch 32, loss 26.128137588500977\n","epoch 33, loss 24.642784118652344\n","epoch 34, loss 23.268301010131836\n","epoch 35, loss 21.992454528808594\n","epoch 36, loss 20.804752349853516\n","Parameter containing:\n","tensor([[0.9517, 0.5615, 0.1898],\n","        [0.2067, 1.3574, 0.2201],\n","        [0.7679, 1.1416, 0.3334],\n","        [0.8112, 1.0064, 0.2604]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1866, 0.7878, 0.7588, 0.6513], requires_grad=True)\n","Parameter containing:\n","tensor([[3.5585, 3.1510, 3.5679, 3.0870]], requires_grad=True)\n","Parameter containing:\n","tensor([4.9473], requires_grad=True)\n","epoch 37, loss 19.696258544921875\n","epoch 38, loss 18.659259796142578\n","epoch 39, loss 17.687177658081055\n","epoch 40, loss 16.774330139160156\n","epoch 41, loss 15.91578483581543\n","Parameter containing:\n","tensor([[1.0093, 0.6639, 0.2207],\n","        [0.2672, 1.4535, 0.2596],\n","        [0.8251, 1.2423, 0.3568],\n","        [0.8679, 1.1024, 0.2807]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1553, 0.7645, 0.7264, 0.6297], requires_grad=True)\n","Parameter containing:\n","tensor([[3.7385, 3.3449, 3.7665, 3.2827]], requires_grad=True)\n","Parameter containing:\n","tensor([5.1074], requires_grad=True)\n","epoch 42, loss 15.107256889343262\n","epoch 43, loss 14.34500789642334\n","epoch 44, loss 13.625722885131836\n","epoch 45, loss 12.946475982666016\n","epoch 46, loss 12.30463695526123\n","Parameter containing:\n","tensor([[1.0580, 0.7566, 0.2576],\n","        [0.3167, 1.5382, 0.2991],\n","        [0.8741, 1.3322, 0.3843],\n","        [0.9164, 1.1881, 0.3049]], requires_grad=True)\n","Parameter containing:\n","tensor([1.1116, 0.7317, 0.6857, 0.5987], requires_grad=True)\n","Parameter containing:\n","tensor([[3.8892, 3.5096, 3.9350, 3.4487]], requires_grad=True)\n","Parameter containing:\n","tensor([5.2345], requires_grad=True)\n","epoch 47, loss 11.69787311553955\n","epoch 48, loss 11.124016761779785\n","epoch 49, loss 10.581153869628906\n","epoch 50, loss 10.067479133605957\n","epoch 51, loss 9.58133602142334\n","Parameter containing:\n","tensor([[1.0985, 0.8396, 0.2972],\n","        [0.3565, 1.6118, 0.3374],\n","        [0.9153, 1.4112, 0.4130],\n","        [0.9573, 1.2636, 0.3302]], requires_grad=True)\n","Parameter containing:\n","tensor([1.0628, 0.6960, 0.6432, 0.5644], requires_grad=True)\n","Parameter containing:\n","tensor([[4.0176, 3.6511, 4.0795, 3.5909]], requires_grad=True)\n","Parameter containing:\n","tensor([5.3383], requires_grad=True)\n","epoch 52, loss 9.121212005615234\n","epoch 53, loss 8.685670852661133\n","epoch 54, loss 8.273386001586914\n","epoch 55, loss 7.883106231689453\n","epoch 56, loss 7.513648986816406\n","Parameter containing:\n","tensor([[1.1317, 0.9131, 0.3375],\n","        [0.3881, 1.6751, 0.3737],\n","        [0.9495, 1.4799, 0.4410],\n","        [0.9914, 1.3294, 0.3554]], requires_grad=True)\n","Parameter containing:\n","tensor([1.0134, 0.6610, 0.6021, 0.5301], requires_grad=True)\n","Parameter containing:\n","tensor([[4.1280, 3.7733, 4.2042, 3.7136]], requires_grad=True)\n","Parameter containing:\n","tensor([5.4252], requires_grad=True)\n","epoch 57, loss 7.163913726806641\n","epoch 58, loss 6.8328471183776855\n","epoch 59, loss 6.519455432891846\n","epoch 60, loss 6.2228007316589355\n","epoch 61, loss 5.9419989585876465\n","Parameter containing:\n","tensor([[1.1588, 0.9778, 0.3768],\n","        [0.4128, 1.7292, 0.4078],\n","        [0.9779, 1.5393, 0.4677],\n","        [1.0198, 1.3865, 0.3797]], requires_grad=True)\n","Parameter containing:\n","tensor([0.9658, 0.6282, 0.5639, 0.4973], requires_grad=True)\n","Parameter containing:\n","tensor([[4.2234, 3.8791, 4.3119, 3.8194]], requires_grad=True)\n","Parameter containing:\n","tensor([5.4990], requires_grad=True)\n","epoch 62, loss 5.676202774047852\n","epoch 63, loss 5.424604415893555\n","epoch 64, loss 5.186455726623535\n","epoch 65, loss 4.961023807525635\n","epoch 66, loss 4.747636318206787\n","Parameter containing:\n","tensor([[1.1806, 1.0344, 0.4146],\n","        [0.4317, 1.7753, 0.4397],\n","        [1.0012, 1.5905, 0.4928],\n","        [1.0433, 1.4359, 0.4027]], requires_grad=True)\n","Parameter containing:\n","tensor([0.9213, 0.5984, 0.5290, 0.4667], requires_grad=True)\n","Parameter containing:\n","tensor([[4.3060, 3.9706, 4.4051, 3.9109]], requires_grad=True)\n","Parameter containing:\n","tensor([5.5624], requires_grad=True)\n","epoch 67, loss 4.545632362365723\n","epoch 68, loss 4.354404926300049\n","epoch 69, loss 4.1733622550964355\n","epoch 70, loss 4.001951694488525\n","epoch 71, loss 3.839649200439453\n","Parameter containing:\n","tensor([[1.1979, 1.0837, 0.4504],\n","        [0.4459, 1.8145, 0.4695],\n","        [1.0202, 1.6347, 0.5163],\n","        [1.0628, 1.4787, 0.4245]], requires_grad=True)\n","Parameter containing:\n","tensor([0.8803, 0.5715, 0.4974, 0.4385], requires_grad=True)\n","Parameter containing:\n","tensor([[4.3775, 4.0499, 4.4856, 3.9900]], requires_grad=True)\n","Parameter containing:\n","tensor([5.6172], requires_grad=True)\n","epoch 72, loss 3.685952663421631\n","epoch 73, loss 3.540391683578491\n","epoch 74, loss 3.402522087097168\n","epoch 75, loss 3.271916151046753\n","epoch 76, loss 3.148176670074463\n","Parameter containing:\n","tensor([[1.2114, 1.1265, 0.4843],\n","        [0.4562, 1.8476, 0.4975],\n","        [1.0358, 1.6727, 0.5383],\n","        [1.0787, 1.5157, 0.4450]], requires_grad=True)\n","Parameter containing:\n","tensor([0.8429, 0.5475, 0.4689, 0.4127], requires_grad=True)\n","Parameter containing:\n","tensor([[4.4393, 4.1185, 4.5552, 4.0583]], requires_grad=True)\n","Parameter containing:\n","tensor([5.6649], requires_grad=True)\n","epoch 77, loss 3.0309197902679443\n","epoch 78, loss 2.919793128967285\n","epoch 79, loss 2.8144454956054688\n","epoch 80, loss 2.7145655155181885\n","epoch 81, loss 2.6198458671569824\n","Parameter containing:\n","tensor([[1.2216, 1.1636, 0.5162],\n","        [0.4632, 1.8756, 0.5239],\n","        [1.0484, 1.7056, 0.5590],\n","        [1.0919, 1.5479, 0.4644]], requires_grad=True)\n","Parameter containing:\n","tensor([0.8089, 0.5262, 0.4431, 0.3891], requires_grad=True)\n","Parameter containing:\n","tensor([[4.4928, 4.1779, 4.6153, 4.1172]], requires_grad=True)\n","Parameter containing:\n","tensor([5.7067], requires_grad=True)\n","epoch 82, loss 2.5299975872039795\n","epoch 83, loss 2.444753408432007\n","epoch 84, loss 2.3638548851013184\n","epoch 85, loss 2.2870593070983887\n","epoch 86, loss 2.2141366004943848\n","Parameter containing:\n","tensor([[1.2291, 1.1957, 0.5463],\n","        [0.4673, 1.8992, 0.5489],\n","        [1.0586, 1.7341, 0.5785],\n","        [1.1025, 1.5758, 0.4828]], requires_grad=True)\n","Parameter containing:\n","tensor([0.7782, 0.5072, 0.4197, 0.3674], requires_grad=True)\n","Parameter containing:\n","tensor([[4.5391, 4.2293, 4.6673, 4.1682]], requires_grad=True)\n","Parameter containing:\n","tensor([5.7434], requires_grad=True)\n","epoch 87, loss 2.144876480102539\n","epoch 88, loss 2.079069137573242\n","epoch 89, loss 2.016524314880371\n","epoch 90, loss 1.957061529159546\n","epoch 91, loss 1.9005056619644165\n","Parameter containing:\n","tensor([[1.2342, 1.2235, 0.5749],\n","        [0.4691, 1.9190, 0.5726],\n","        [1.0666, 1.7588, 0.5970],\n","        [1.1112, 1.6001, 0.5003]], requires_grad=True)\n","Parameter containing:\n","tensor([0.7504, 0.4903, 0.3984, 0.3475], requires_grad=True)\n","Parameter containing:\n","tensor([[4.5792, 4.2739, 4.7123, 4.2122]], requires_grad=True)\n","Parameter containing:\n","tensor([5.7759], requires_grad=True)\n","epoch 92, loss 1.8466988801956177\n","epoch 93, loss 1.7954857349395752\n","epoch 94, loss 1.74672532081604\n","epoch 95, loss 1.700278401374817\n","epoch 96, loss 1.6560195684432983\n","Parameter containing:\n","tensor([[1.2372, 1.2475, 0.6019],\n","        [0.4688, 1.9355, 0.5954],\n","        [1.0729, 1.7802, 0.6145],\n","        [1.1181, 1.6213, 0.5169]], requires_grad=True)\n","Parameter containing:\n","tensor([0.7252, 0.4753, 0.3790, 0.3292], requires_grad=True)\n","Parameter containing:\n","tensor([[4.6139, 4.3126, 4.7512, 4.2502]], requires_grad=True)\n","Parameter containing:\n","tensor([5.8049], requires_grad=True)\n","epoch 97, loss 1.6138259172439575\n","epoch 98, loss 1.5735833644866943\n","epoch 99, loss 1.5351847410202026\n","epoch 100, loss 1.498528242111206\n","epoch 101, loss 1.4635220766067505\n","Parameter containing:\n","tensor([[1.2386, 1.2682, 0.6277],\n","        [0.4668, 1.9492, 0.6173],\n","        [1.0777, 1.7989, 0.6312],\n","        [1.1236, 1.6398, 0.5328]], requires_grad=True)\n","Parameter containing:\n","tensor([0.7023, 0.4620, 0.3612, 0.3123], requires_grad=True)\n","Parameter containing:\n","tensor([[4.6439, 4.3463, 4.7849, 4.2832]], requires_grad=True)\n","Parameter containing:\n","tensor([5.8309], requires_grad=True)\n","epoch 102, loss 1.4300717115402222\n","epoch 103, loss 1.3980939388275146\n","epoch 104, loss 1.3675053119659424\n","epoch 105, loss 1.338235855102539\n","epoch 106, loss 1.3102105855941772\n","Parameter containing:\n","tensor([[1.2384, 1.2861, 0.6523],\n","        [0.4633, 1.9604, 0.6383],\n","        [1.0813, 1.8153, 0.6472],\n","        [1.1278, 1.6561, 0.5480]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6816, 0.4502, 0.3448, 0.2967], requires_grad=True)\n","Parameter containing:\n","tensor([[4.6700, 4.3756, 4.8142, 4.3118]], requires_grad=True)\n","Parameter containing:\n","tensor([5.8543], requires_grad=True)\n","epoch 107, loss 1.2833610773086548\n","epoch 108, loss 1.2576278448104858\n","epoch 109, loss 1.2329494953155518\n","epoch 110, loss 1.2092677354812622\n","epoch 111, loss 1.186531662940979\n","Parameter containing:\n","tensor([[1.2370, 1.3015, 0.6759],\n","        [0.4585, 1.9694, 0.6586],\n","        [1.0838, 1.8297, 0.6625],\n","        [1.1310, 1.6705, 0.5626]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6627, 0.4397, 0.3298, 0.2822], requires_grad=True)\n","Parameter containing:\n","tensor([[4.6926, 4.4013, 4.8397, 4.3367]], requires_grad=True)\n","Parameter containing:\n","tensor([5.8756], requires_grad=True)\n","epoch 112, loss 1.164689064025879\n","epoch 113, loss 1.1436959505081177\n","epoch 114, loss 1.1235052347183228\n","epoch 115, loss 1.1040749549865723\n","epoch 116, loss 1.0853662490844727\n","Parameter containing:\n","tensor([[1.2345, 1.3148, 0.6985],\n","        [0.4525, 1.9767, 0.6783],\n","        [1.0855, 1.8423, 0.6771],\n","        [1.1333, 1.6833, 0.5765]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6455, 0.4305, 0.3159, 0.2687], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7124, 4.4239, 4.8620, 4.3584]], requires_grad=True)\n","Parameter containing:\n","tensor([5.8951], requires_grad=True)\n","epoch 117, loss 1.0673400163650513\n","epoch 118, loss 1.0499643087387085\n","epoch 119, loss 1.033203125\n","epoch 120, loss 1.017025351524353\n","epoch 121, loss 1.0014004707336426\n","Parameter containing:\n","tensor([[1.2310, 1.3262, 0.7202],\n","        [0.4456, 1.9823, 0.6975],\n","        [1.0864, 1.8535, 0.6912],\n","        [1.1349, 1.6946, 0.5899]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6298, 0.4224, 0.3030, 0.2561], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7297, 4.4437, 4.8815, 4.3773]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9130], requires_grad=True)\n","epoch 122, loss 0.9863030910491943\n","epoch 123, loss 0.9717069268226624\n","epoch 124, loss 0.9575842618942261\n","epoch 125, loss 0.9439116716384888\n","epoch 126, loss 0.9306705594062805\n","Parameter containing:\n","tensor([[1.2268, 1.3361, 0.7411],\n","        [0.4378, 1.9866, 0.7161],\n","        [1.0867, 1.8635, 0.7047],\n","        [1.1359, 1.7047, 0.6028]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6154, 0.4153, 0.2910, 0.2444], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7448, 4.4613, 4.8986, 4.3939]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9296], requires_grad=True)\n","epoch 127, loss 0.9178369045257568\n","epoch 128, loss 0.905392050743103\n","epoch 129, loss 0.8933166861534119\n","epoch 130, loss 0.881593644618988\n","epoch 131, loss 0.8702069520950317\n","Parameter containing:\n","tensor([[1.2219, 1.3447, 0.7613],\n","        [0.4292, 1.9897, 0.7342],\n","        [1.0865, 1.8724, 0.7177],\n","        [1.1364, 1.7139, 0.6152]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6023, 0.4091, 0.2798, 0.2334], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7581, 4.4769, 4.9137, 4.4085]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9450], requires_grad=True)\n","epoch 132, loss 0.8591408133506775\n","epoch 133, loss 0.8483779430389404\n","epoch 134, loss 0.8379076719284058\n","epoch 135, loss 0.8277152180671692\n","epoch 136, loss 0.8177877068519592\n","Parameter containing:\n","tensor([[1.2164, 1.3521, 0.7807],\n","        [0.4200, 1.9918, 0.7518],\n","        [1.0859, 1.8805, 0.7302],\n","        [1.1365, 1.7222, 0.6270]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5902, 0.4038, 0.2694, 0.2231], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7699, 4.4908, 4.9270, 4.4214]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9594], requires_grad=True)\n","epoch 137, loss 0.8081143498420715\n","epoch 138, loss 0.7986839413642883\n","epoch 139, loss 0.7894847393035889\n","epoch 140, loss 0.7805083394050598\n","epoch 141, loss 0.7717441916465759\n","Parameter containing:\n","tensor([[1.2105, 1.3586, 0.7995],\n","        [0.4103, 1.9930, 0.7691],\n","        [1.0849, 1.8879, 0.7421],\n","        [1.1363, 1.7299, 0.6384]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5792, 0.3992, 0.2596, 0.2134], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7803, 4.5033, 4.9388, 4.4328]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9729], requires_grad=True)\n","epoch 142, loss 0.7631837725639343\n","epoch 143, loss 0.7548184990882874\n","epoch 144, loss 0.7466407418251038\n","epoch 145, loss 0.7386422157287598\n","epoch 146, loss 0.7308167219161987\n","Parameter containing:\n","tensor([[1.2042, 1.3643, 0.8176],\n","        [0.4000, 1.9934, 0.7859],\n","        [1.0837, 1.8947, 0.7536],\n","        [1.1358, 1.7369, 0.6494]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5691, 0.3954, 0.2505, 0.2042], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7896, 4.5146, 4.9494, 4.4429]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9856], requires_grad=True)\n","epoch 147, loss 0.7231569290161133\n","epoch 148, loss 0.7156566381454468\n","epoch 149, loss 0.7083097696304321\n","epoch 150, loss 0.7011100649833679\n","epoch 151, loss 0.6940525770187378\n","Parameter containing:\n","tensor([[1.1976, 1.3693, 0.8351],\n","        [0.3893, 1.9933, 0.8023],\n","        [1.0824, 1.9010, 0.7647],\n","        [1.1351, 1.7435, 0.6598]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5598, 0.3922, 0.2419, 0.1957], requires_grad=True)\n","Parameter containing:\n","tensor([[4.7979, 4.5248, 4.9588, 4.4520]], requires_grad=True)\n","Parameter containing:\n","tensor([5.9976], requires_grad=True)\n","epoch 152, loss 0.6871324181556702\n","epoch 153, loss 0.6803449392318726\n","epoch 154, loss 0.673684298992157\n","epoch 155, loss 0.6671465039253235\n","epoch 156, loss 0.6607283353805542\n","Parameter containing:\n","tensor([[1.1908, 1.3738, 0.8520],\n","        [0.3783, 1.9926, 0.8184],\n","        [1.0808, 1.9070, 0.7753],\n","        [1.1343, 1.7498, 0.6699]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5513, 0.3897, 0.2339, 0.1875], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8054, 4.5342, 4.9673, 4.4601]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0089], requires_grad=True)\n","epoch 157, loss 0.6544249653816223\n","epoch 158, loss 0.6482323408126831\n","epoch 159, loss 0.6421471834182739\n","epoch 160, loss 0.636166512966156\n","epoch 161, loss 0.6302865743637085\n","Parameter containing:\n","tensor([[1.1838, 1.3779, 0.8684],\n","        [0.3669, 1.9915, 0.8341],\n","        [1.0792, 1.9126, 0.7854],\n","        [1.1334, 1.7557, 0.6795]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5435, 0.3878, 0.2263, 0.1799], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8122, 4.5428, 4.9750, 4.4675]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0195], requires_grad=True)\n","epoch 162, loss 0.6245051026344299\n","epoch 163, loss 0.6188179850578308\n","epoch 164, loss 0.6132229566574097\n","epoch 165, loss 0.6077180504798889\n","epoch 166, loss 0.6022993326187134\n","Parameter containing:\n","tensor([[1.1767, 1.3817, 0.8842],\n","        [0.3553, 1.9900, 0.8494],\n","        [1.0776, 1.9180, 0.7952],\n","        [1.1325, 1.7614, 0.6887]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5364, 0.3864, 0.2192, 0.1726], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8183, 4.5507, 4.9820, 4.4741]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0296], requires_grad=True)\n","epoch 167, loss 0.5969647169113159\n","epoch 168, loss 0.5917136669158936\n","epoch 169, loss 0.5865413546562195\n","epoch 170, loss 0.5814468264579773\n","epoch 171, loss 0.5764287710189819\n","Parameter containing:\n","tensor([[1.1696, 1.3852, 0.8994],\n","        [0.3435, 1.9882, 0.8644],\n","        [1.0759, 1.9233, 0.8045],\n","        [1.1315, 1.7670, 0.6975]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5298, 0.3855, 0.2124, 0.1657], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8238, 4.5580, 4.9884, 4.4802]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0392], requires_grad=True)\n","epoch 172, loss 0.5714844465255737\n","epoch 173, loss 0.5666118860244751\n","epoch 174, loss 0.561809778213501\n","epoch 175, loss 0.5570757389068604\n","epoch 176, loss 0.5524095296859741\n","Parameter containing:\n","tensor([[1.1624, 1.3886, 0.9141],\n","        [0.3315, 1.9863, 0.8790],\n","        [1.0743, 1.9284, 0.8134],\n","        [1.1305, 1.7724, 0.7060]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5238, 0.3851, 0.2060, 0.1592], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8289, 4.5649, 4.9942, 4.4857]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0482], requires_grad=True)\n","epoch 177, loss 0.5478078126907349\n","epoch 178, loss 0.5432705879211426\n","epoch 179, loss 0.5387952327728271\n","epoch 180, loss 0.5343812704086304\n","epoch 181, loss 0.530026376247406\n","Parameter containing:\n","tensor([[1.1553, 1.3919, 0.9283],\n","        [0.3194, 1.9842, 0.8933],\n","        [1.0727, 1.9335, 0.8219],\n","        [1.1296, 1.7778, 0.7140]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5183, 0.3851, 0.2000, 0.1530], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8336, 4.5713, 4.9996, 4.4907]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0567], requires_grad=True)\n","epoch 182, loss 0.5257300734519958\n","epoch 183, loss 0.5214914083480835\n","epoch 184, loss 0.517307698726654\n","epoch 185, loss 0.5131787061691284\n","epoch 186, loss 0.5091038942337036\n","Parameter containing:\n","tensor([[1.1482, 1.3951, 0.9419],\n","        [0.3071, 1.9819, 0.9072],\n","        [1.0711, 1.9386, 0.8300],\n","        [1.1287, 1.7831, 0.7216]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5133, 0.3855, 0.1943, 0.1471], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8378, 4.5773, 5.0045, 4.4954]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0647], requires_grad=True)\n","epoch 187, loss 0.5050814151763916\n","epoch 188, loss 0.5011103749275208\n","epoch 189, loss 0.49718964099884033\n","epoch 190, loss 0.49331846833229065\n","epoch 191, loss 0.4894954562187195\n","Parameter containing:\n","tensor([[1.1412, 1.3983, 0.9551],\n","        [0.2948, 1.9796, 0.9208],\n","        [1.0697, 1.9436, 0.8378],\n","        [1.1279, 1.7884, 0.7289]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5087, 0.3864, 0.1889, 0.1415], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8418, 4.5830, 5.0091, 4.4996]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0723], requires_grad=True)\n","epoch 192, loss 0.48572036623954773\n","epoch 193, loss 0.48199161887168884\n","epoch 194, loss 0.47830861806869507\n","epoch 195, loss 0.47467026114463806\n","epoch 196, loss 0.471076101064682\n","Parameter containing:\n","tensor([[1.1344, 1.4015, 0.9678],\n","        [0.2825, 1.9772, 0.9341],\n","        [1.0683, 1.9487, 0.8451],\n","        [1.1272, 1.7937, 0.7358]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5046, 0.3876, 0.1838, 0.1361], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8454, 4.5884, 5.0134, 4.5036]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0794], requires_grad=True)\n","epoch 197, loss 0.4675246775150299\n","epoch 198, loss 0.4640160799026489\n","epoch 199, loss 0.4605492651462555\n","epoch 200, loss 0.45712369680404663\n","epoch 201, loss 0.4537374973297119\n","Parameter containing:\n","tensor([[1.1276, 1.4049, 0.9800],\n","        [0.2701, 1.9749, 0.9471],\n","        [1.0671, 1.9538, 0.8522],\n","        [1.1265, 1.7991, 0.7424]], requires_grad=True)\n","Parameter containing:\n","tensor([0.5008, 0.3891, 0.1789, 0.1310], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8488, 4.5934, 5.0173, 4.5073]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0861], requires_grad=True)\n","epoch 202, loss 0.4503905475139618\n","epoch 203, loss 0.4470832347869873\n","epoch 204, loss 0.44381314516067505\n","epoch 205, loss 0.44058096408843994\n","epoch 206, loss 0.43738508224487305\n","Parameter containing:\n","tensor([[1.1210, 1.4083, 0.9917],\n","        [0.2577, 1.9726, 0.9598],\n","        [1.0659, 1.9589, 0.8588],\n","        [1.1260, 1.8045, 0.7487]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4974, 0.3910, 0.1743, 0.1261], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8519, 4.5983, 5.0210, 4.5107]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0923], requires_grad=True)\n","epoch 207, loss 0.43422508239746094\n","epoch 208, loss 0.4311007559299469\n","epoch 209, loss 0.42801129817962646\n","epoch 210, loss 0.42495599389076233\n","epoch 211, loss 0.42193466424942017\n","Parameter containing:\n","tensor([[1.1146, 1.4118, 1.0030],\n","        [0.2453, 1.9703, 0.9721],\n","        [1.0649, 1.9642, 0.8652],\n","        [1.1255, 1.8099, 0.7546]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4942, 0.3932, 0.1698, 0.1215], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8548, 4.6029, 5.0245, 4.5139]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0981], requires_grad=True)\n","epoch 212, loss 0.418945848941803\n","epoch 213, loss 0.41598913073539734\n","epoch 214, loss 0.41306495666503906\n","epoch 215, loss 0.41017210483551025\n","epoch 216, loss 0.40730932354927063\n","Parameter containing:\n","tensor([[1.1083, 1.4154, 1.0138],\n","        [0.2330, 1.9680, 0.9841],\n","        [1.0640, 1.9695, 0.8712],\n","        [1.1252, 1.8154, 0.7602]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4914, 0.3957, 0.1656, 0.1170], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8575, 4.6073, 5.0277, 4.5169]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1035], requires_grad=True)\n","epoch 217, loss 0.40447771549224854\n","epoch 218, loss 0.4016750454902649\n","epoch 219, loss 0.39890238642692566\n","epoch 220, loss 0.3961578607559204\n","epoch 221, loss 0.393441766500473\n","Parameter containing:\n","tensor([[1.1023, 1.4192, 1.0242],\n","        [0.2207, 1.9659, 0.9959],\n","        [1.0633, 1.9748, 0.8769],\n","        [1.1250, 1.8210, 0.7656]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4889, 0.3984, 0.1616, 0.1127], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8599, 4.6115, 5.0308, 4.5196]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1085], requires_grad=True)\n","epoch 222, loss 0.3907533288002014\n","epoch 223, loss 0.3880922496318817\n","epoch 224, loss 0.3854585587978363\n","epoch 225, loss 0.3828510344028473\n","epoch 226, loss 0.3802691698074341\n","Parameter containing:\n","tensor([[1.0964, 1.4231, 1.0342],\n","        [0.2085, 1.9638, 1.0073],\n","        [1.0626, 1.9803, 0.8823],\n","        [1.1249, 1.8266, 0.7706]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4866, 0.4014, 0.1578, 0.1087], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8622, 4.6155, 5.0336, 4.5222]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1131], requires_grad=True)\n","epoch 227, loss 0.37771281599998474\n","epoch 228, loss 0.37518155574798584\n","epoch 229, loss 0.3726751506328583\n","epoch 230, loss 0.37019309401512146\n","epoch 231, loss 0.36773422360420227\n","Parameter containing:\n","tensor([[1.0908, 1.4272, 1.0438],\n","        [0.1963, 1.9619, 1.0185],\n","        [1.0621, 1.9858, 0.8874],\n","        [1.1249, 1.8323, 0.7754]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4846, 0.4045, 0.1541, 0.1047], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8643, 4.6193, 5.0363, 4.5246]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1174], requires_grad=True)\n","epoch 232, loss 0.36529916524887085\n","epoch 233, loss 0.3628871738910675\n","epoch 234, loss 0.3604978322982788\n","epoch 235, loss 0.3581307530403137\n","epoch 236, loss 0.3557855188846588\n","Parameter containing:\n","tensor([[1.0853, 1.4314, 1.0530],\n","        [0.1842, 1.9601, 1.0294],\n","        [1.0618, 1.9914, 0.8922],\n","        [1.1250, 1.8381, 0.7799]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4827, 0.4079, 0.1506, 0.1010], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8663, 4.6230, 5.0388, 4.5269]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1212], requires_grad=True)\n","epoch 237, loss 0.35346198081970215\n","epoch 238, loss 0.35115915536880493\n","epoch 239, loss 0.34887760877609253\n","epoch 240, loss 0.3466161787509918\n","epoch 241, loss 0.344375878572464\n","Parameter containing:\n","tensor([[1.0800, 1.4358, 1.0618],\n","        [0.1723, 1.9583, 1.0400],\n","        [1.0615, 1.9971, 0.8968],\n","        [1.1253, 1.8439, 0.7841]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4811, 0.4115, 0.1473, 0.0973], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8681, 4.6265, 5.0412, 4.5290]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1248], requires_grad=True)\n","epoch 242, loss 0.34215444326400757\n","epoch 243, loss 0.3399530351161957\n","epoch 244, loss 0.33777064085006714\n","epoch 245, loss 0.3356070816516876\n","epoch 246, loss 0.3334616422653198\n","Parameter containing:\n","tensor([[1.0750, 1.4403, 1.0702],\n","        [0.1604, 1.9567, 1.0503],\n","        [1.0614, 2.0028, 0.9011],\n","        [1.1256, 1.8498, 0.7881]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4796, 0.4153, 0.1441, 0.0938], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8697, 4.6299, 5.0435, 4.5310]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1280], requires_grad=True)\n","epoch 247, loss 0.33133524656295776\n","epoch 248, loss 0.32922643423080444\n","epoch 249, loss 0.3271351456642151\n","epoch 250, loss 0.32506150007247925\n","epoch 251, loss 0.32300493121147156\n","Parameter containing:\n","tensor([[1.0701, 1.4450, 1.0783],\n","        [0.1486, 1.9553, 1.0604],\n","        [1.0614, 2.0086, 0.9052],\n","        [1.1260, 1.8557, 0.7919]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4784, 0.4193, 0.1410, 0.0905], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8712, 4.6331, 5.0456, 4.5329]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1308], requires_grad=True)\n","epoch 252, loss 0.3209651708602905\n","epoch 253, loss 0.31894150376319885\n","epoch 254, loss 0.31693539023399353\n","epoch 255, loss 0.3149445652961731\n","epoch 256, loss 0.3129699230194092\n","Parameter containing:\n","tensor([[1.0655, 1.4498, 1.0861],\n","        [0.1370, 1.9539, 1.0702],\n","        [1.0615, 2.0145, 0.9091],\n","        [1.1266, 1.8616, 0.7955]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4772, 0.4233, 0.1380, 0.0872], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8726, 4.6362, 5.0475, 4.5346]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1334], requires_grad=True)\n","epoch 257, loss 0.3110097646713257\n","epoch 258, loss 0.3090660870075226\n","epoch 259, loss 0.30713728070259094\n","epoch 260, loss 0.30522361397743225\n","epoch 261, loss 0.3033241629600525\n","Parameter containing:\n","tensor([[1.0610, 1.4547, 1.0935],\n","        [0.1254, 1.9527, 1.0798],\n","        [1.0617, 2.0204, 0.9127],\n","        [1.1272, 1.8676, 0.7988]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4763, 0.4276, 0.1352, 0.0841], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8739, 4.6392, 5.0494, 4.5362]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1356], requires_grad=True)\n","epoch 262, loss 0.30143970251083374\n","epoch 263, loss 0.299568235874176\n","epoch 264, loss 0.2977118194103241\n","epoch 265, loss 0.29586896300315857\n","epoch 266, loss 0.29404008388519287\n","Parameter containing:\n","tensor([[1.0568, 1.4598, 1.1006],\n","        [0.1140, 1.9516, 1.0891],\n","        [1.0620, 2.0264, 0.9162],\n","        [1.1279, 1.8737, 0.8020]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4754, 0.4319, 0.1324, 0.0811], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8750, 4.6420, 5.0511, 4.5377]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1376], requires_grad=True)\n","epoch 267, loss 0.29222458600997925\n","epoch 268, loss 0.29042142629623413\n","epoch 269, loss 0.2886325418949127\n","epoch 270, loss 0.2868557572364807\n","epoch 271, loss 0.2850917875766754\n","Parameter containing:\n","tensor([[1.0527, 1.4649, 1.1074],\n","        [0.1028, 1.9506, 1.0982],\n","        [1.0624, 2.0324, 0.9194],\n","        [1.1287, 1.8797, 0.8050]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4747, 0.4364, 0.1298, 0.0782], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8760, 4.6447, 5.0528, 4.5392]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1393], requires_grad=True)\n","epoch 272, loss 0.2833404242992401\n","epoch 273, loss 0.2816011309623718\n","epoch 274, loss 0.2798742949962616\n","epoch 275, loss 0.27815955877304077\n","epoch 276, loss 0.27645590901374817\n","Parameter containing:\n","tensor([[1.0489, 1.4702, 1.1139],\n","        [0.0916, 1.9497, 1.1071],\n","        [1.0629, 2.0384, 0.9224],\n","        [1.1296, 1.8858, 0.8078]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4740, 0.4409, 0.1273, 0.0754], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8769, 4.6474, 5.0543, 4.5405]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1407], requires_grad=True)\n","epoch 277, loss 0.2747645080089569\n","epoch 278, loss 0.2730848491191864\n","epoch 279, loss 0.2714165449142456\n","epoch 280, loss 0.269758939743042\n","epoch 281, loss 0.2681126594543457\n","Parameter containing:\n","tensor([[1.0452, 1.4756, 1.1202],\n","        [0.0806, 1.9490, 1.1157],\n","        [1.0634, 2.0444, 0.9253],\n","        [1.1305, 1.8919, 0.8104]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4735, 0.4456, 0.1248, 0.0727], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8778, 4.6499, 5.0557, 4.5417]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1419], requires_grad=True)\n","epoch 282, loss 0.2664777338504791\n","epoch 283, loss 0.2648533880710602\n","epoch 284, loss 0.2632398307323456\n","epoch 285, loss 0.2616364061832428\n","epoch 286, loss 0.2600436806678772\n","Parameter containing:\n","tensor([[1.0417, 1.4810, 1.1262],\n","        [0.0697, 1.9483, 1.1242],\n","        [1.0641, 2.0505, 0.9280],\n","        [1.1315, 1.8979, 0.8129]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4731, 0.4503, 0.1224, 0.0700], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8785, 4.6522, 5.0571, 4.5428]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1429], requires_grad=True)\n","epoch 287, loss 0.25846144556999207\n","epoch 288, loss 0.2568892538547516\n","epoch 289, loss 0.2553267180919647\n","epoch 290, loss 0.25377437472343445\n","epoch 291, loss 0.2522321045398712\n","Parameter containing:\n","tensor([[1.0383, 1.4866, 1.1319],\n","        [0.0590, 1.9478, 1.1324],\n","        [1.0648, 2.0565, 0.9306],\n","        [1.1326, 1.9040, 0.8152]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4727, 0.4551, 0.1202, 0.0675], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8791, 4.6545, 5.0584, 4.5439]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1436], requires_grad=True)\n","epoch 292, loss 0.25069981813430786\n","epoch 293, loss 0.2491769790649414\n","epoch 294, loss 0.24766366183757782\n","epoch 295, loss 0.24615922570228577\n","epoch 296, loss 0.2446649670600891\n","Parameter containing:\n","tensor([[1.0352, 1.4922, 1.1374],\n","        [0.0484, 1.9474, 1.1404],\n","        [1.0656, 2.0626, 0.9330],\n","        [1.1337, 1.9101, 0.8174]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4724, 0.4599, 0.1179, 0.0650], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8796, 4.6567, 5.0595, 4.5448]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1442], requires_grad=True)\n","epoch 297, loss 0.24317918717861176\n","epoch 298, loss 0.24170340597629547\n","epoch 299, loss 0.2402360886335373\n","epoch 300, loss 0.23877739906311035\n","epoch 301, loss 0.23732836544513702\n","Parameter containing:\n","tensor([[1.0322, 1.4979, 1.1427],\n","        [0.0380, 1.9471, 1.1482],\n","        [1.0665, 2.0687, 0.9352],\n","        [1.1349, 1.9161, 0.8195]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4722, 0.4648, 0.1158, 0.0627], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8801, 4.6588, 5.0607, 4.5458]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1445], requires_grad=True)\n","epoch 302, loss 0.23588791489601135\n","epoch 303, loss 0.2344551384449005\n","epoch 304, loss 0.2330322414636612\n","epoch 305, loss 0.2316172569990158\n","epoch 306, loss 0.23021136224269867\n","Parameter containing:\n","tensor([[1.0293, 1.5036, 1.1477],\n","        [0.0277, 1.9469, 1.1559],\n","        [1.0674, 2.0747, 0.9374],\n","        [1.1361, 1.9222, 0.8214]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4720, 0.4698, 0.1137, 0.0603], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8805, 4.6609, 5.0617, 4.5466]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1446], requires_grad=True)\n","epoch 307, loss 0.2288130223751068\n","epoch 308, loss 0.2274235486984253\n","epoch 309, loss 0.22604216635227203\n","epoch 310, loss 0.2246687263250351\n","epoch 311, loss 0.22330403327941895\n","Parameter containing:\n","tensor([[1.0266, 1.5094, 1.1525],\n","        [0.0176, 1.9468, 1.1633],\n","        [1.0684, 2.0807, 0.9394],\n","        [1.1374, 1.9282, 0.8232]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4719, 0.4747, 0.1117, 0.0581], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8808, 4.6628, 5.0626, 4.5473]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1446], requires_grad=True)\n","epoch 312, loss 0.22194704413414001\n","epoch 313, loss 0.22059780359268188\n","epoch 314, loss 0.2192564159631729\n","epoch 315, loss 0.2179228812456131\n","epoch 316, loss 0.21659694612026215\n","Parameter containing:\n","tensor([[1.0241, 1.5152, 1.1571],\n","        [0.0076, 1.9467, 1.1706],\n","        [1.0695, 2.0867, 0.9412],\n","        [1.1387, 1.9342, 0.8249]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4718, 0.4797, 0.1098, 0.0559], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8810, 4.6646, 5.0635, 4.5481]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1444], requires_grad=True)\n","epoch 317, loss 0.21527940034866333\n","epoch 318, loss 0.21396906673908234\n","epoch 319, loss 0.2126666009426117\n","epoch 320, loss 0.21137124300003052\n","epoch 321, loss 0.21008342504501343\n","Parameter containing:\n","tensor([[ 1.0217,  1.5211,  1.1616],\n","        [-0.0023,  1.9468,  1.1777],\n","        [ 1.0706,  2.0927,  0.9430],\n","        [ 1.1400,  1.9401,  0.8265]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4718, 0.4848, 0.1079, 0.0538], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8812, 4.6664, 5.0644, 4.5487]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1440], requires_grad=True)\n","epoch 322, loss 0.2088032215833664\n","epoch 323, loss 0.2075299769639969\n","epoch 324, loss 0.20626480877399445\n","epoch 325, loss 0.20500606298446655\n","epoch 326, loss 0.20375534892082214\n","Parameter containing:\n","tensor([[ 1.0194,  1.5270,  1.1658],\n","        [-0.0120,  1.9470,  1.1846],\n","        [ 1.0717,  2.0987,  0.9446],\n","        [ 1.1414,  1.9460,  0.8280]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4719, 0.4898, 0.1061, 0.0518], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8813, 4.6681, 5.0652, 4.5493]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1435], requires_grad=True)\n","epoch 327, loss 0.2025115042924881\n","epoch 328, loss 0.20127452909946442\n","epoch 329, loss 0.20004475116729736\n","epoch 330, loss 0.19882196187973022\n","epoch 331, loss 0.19760654866695404\n","Parameter containing:\n","tensor([[ 1.0173,  1.5329,  1.1698],\n","        [-0.0215,  1.9472,  1.1914],\n","        [ 1.0729,  2.1046,  0.9462],\n","        [ 1.1428,  1.9519,  0.8294]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4719, 0.4948, 0.1043, 0.0498], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8814, 4.6697, 5.0659, 4.5498]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1429], requires_grad=True)\n","epoch 332, loss 0.19639737904071808\n","epoch 333, loss 0.19519588351249695\n","epoch 334, loss 0.19400061666965485\n","epoch 335, loss 0.1928124874830246\n","epoch 336, loss 0.19163140654563904\n","Parameter containing:\n","tensor([[ 1.0152,  1.5388,  1.1737],\n","        [-0.0309,  1.9475,  1.1979],\n","        [ 1.0741,  2.1104,  0.9477],\n","        [ 1.1442,  1.9577,  0.8307]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4720, 0.4999, 0.1026, 0.0478], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8814, 4.6713, 5.0666, 4.5503]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1421], requires_grad=True)\n","epoch 337, loss 0.19045624136924744\n","epoch 338, loss 0.18928836286067963\n","epoch 339, loss 0.1881268471479416\n","epoch 340, loss 0.18697182834148407\n","epoch 341, loss 0.18582364916801453\n","Parameter containing:\n","tensor([[ 1.0133,  1.5447,  1.1775],\n","        [-0.0402,  1.9479,  1.2044],\n","        [ 1.0753,  2.1163,  0.9490],\n","        [ 1.1457,  1.9635,  0.8319]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4721, 0.5049, 0.1010, 0.0459], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8813, 4.6728, 5.0672, 4.5508]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1413], requires_grad=True)\n","epoch 342, loss 0.1846819818019867\n","epoch 343, loss 0.18354660272598267\n","epoch 344, loss 0.18241789937019348\n","epoch 345, loss 0.1812955141067505\n","epoch 346, loss 0.18017934262752533\n","Parameter containing:\n","tensor([[ 1.0116,  1.5506,  1.1810],\n","        [-0.0493,  1.9484,  1.2106],\n","        [ 1.0766,  2.1220,  0.9503],\n","        [ 1.1471,  1.9692,  0.8330]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4723, 0.5099, 0.0993, 0.0441], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8813, 4.6742, 5.0678, 4.5512]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1403], requires_grad=True)\n","epoch 347, loss 0.17907001078128815\n","epoch 348, loss 0.17796698212623596\n","epoch 349, loss 0.17686961591243744\n","epoch 350, loss 0.1757792830467224\n","epoch 351, loss 0.17469462752342224\n","Parameter containing:\n","tensor([[ 1.0099,  1.5565,  1.1845],\n","        [-0.0582,  1.9489,  1.2168],\n","        [ 1.0779,  2.1278,  0.9515],\n","        [ 1.1486,  1.9749,  0.8341]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4724, 0.5150, 0.0978, 0.0423], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8811, 4.6756, 5.0683, 4.5515]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1392], requires_grad=True)\n","epoch 352, loss 0.17361636459827423\n","epoch 353, loss 0.1725437343120575\n","epoch 354, loss 0.17147766053676605\n","epoch 355, loss 0.1704179346561432\n","epoch 356, loss 0.1693641096353531\n","Parameter containing:\n","tensor([[ 1.0083,  1.5624,  1.1877],\n","        [-0.0670,  1.9495,  1.2228],\n","        [ 1.0792,  2.1335,  0.9526],\n","        [ 1.1501,  1.9805,  0.8351]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4726, 0.5200, 0.0963, 0.0406], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8810, 4.6769, 5.0688, 4.5519]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1380], requires_grad=True)\n","epoch 357, loss 0.16831646859645844\n","epoch 358, loss 0.16727425158023834\n","epoch 359, loss 0.16623836755752563\n","epoch 360, loss 0.1652083545923233\n","epoch 361, loss 0.1641845703125\n","Parameter containing:\n","tensor([[ 1.0068,  1.5683,  1.1909],\n","        [-0.0757,  1.9502,  1.2286],\n","        [ 1.0805,  2.1391,  0.9537],\n","        [ 1.1517,  1.9861,  0.8360]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4728, 0.5249, 0.0948, 0.0389], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8808, 4.6781, 5.0692, 4.5521]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1367], requires_grad=True)\n","epoch 362, loss 0.1631665825843811\n","epoch 363, loss 0.16215375065803528\n","epoch 364, loss 0.16114729642868042\n","epoch 365, loss 0.1601465344429016\n","epoch 366, loss 0.1591518372297287\n","Parameter containing:\n","tensor([[ 1.0054,  1.5741,  1.1939],\n","        [-0.0842,  1.9509,  1.2343],\n","        [ 1.0818,  2.1447,  0.9547],\n","        [ 1.1532,  1.9916,  0.8369]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4730, 0.5299, 0.0933, 0.0373], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8805, 4.6793, 5.0696, 4.5524]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1354], requires_grad=True)\n","epoch 367, loss 0.1581626832485199\n","epoch 368, loss 0.15717893838882446\n","epoch 369, loss 0.15620112419128418\n","epoch 370, loss 0.1552291363477707\n","epoch 371, loss 0.1542627215385437\n","Parameter containing:\n","tensor([[ 1.0041,  1.5799,  1.1968],\n","        [-0.0925,  1.9517,  1.2399],\n","        [ 1.0832,  2.1502,  0.9556],\n","        [ 1.1547,  1.9970,  0.8377]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4733, 0.5348, 0.0919, 0.0357], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8802, 4.6805, 5.0700, 4.5526]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1339], requires_grad=True)\n","epoch 372, loss 0.15330156683921814\n","epoch 373, loss 0.15234632790088654\n","epoch 374, loss 0.1513969600200653\n","epoch 375, loss 0.15045185387134552\n","epoch 376, loss 0.1495130956172943\n","Parameter containing:\n","tensor([[ 1.0029,  1.5857,  1.1996],\n","        [-0.1008,  1.9526,  1.2453],\n","        [ 1.0846,  2.1556,  0.9564],\n","        [ 1.1562,  2.0024,  0.8384]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4735, 0.5397, 0.0906, 0.0342], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8799, 4.6816, 5.0704, 4.5528]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1324], requires_grad=True)\n","epoch 377, loss 0.14857953786849976\n","epoch 378, loss 0.1476522982120514\n","epoch 379, loss 0.14672963321208954\n","epoch 380, loss 0.14581269025802612\n","epoch 381, loss 0.14490097761154175\n","Parameter containing:\n","tensor([[ 1.0018,  1.5915,  1.2022],\n","        [-0.1088,  1.9534,  1.2506],\n","        [ 1.0860,  2.1610,  0.9572],\n","        [ 1.1578,  2.0077,  0.8391]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4738, 0.5446, 0.0893, 0.0327], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8796, 4.6827, 5.0707, 4.5530]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1309], requires_grad=True)\n","epoch 382, loss 0.1439943164587021\n","epoch 383, loss 0.1430935263633728\n","epoch 384, loss 0.14219745993614197\n","epoch 385, loss 0.14130738377571106\n","epoch 386, loss 0.14042194187641144\n","Parameter containing:\n","tensor([[ 1.0008,  1.5972,  1.2048],\n","        [-0.1168,  1.9544,  1.2558],\n","        [ 1.0874,  2.1663,  0.9580],\n","        [ 1.1593,  2.0129,  0.8397]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4741, 0.5494, 0.0880, 0.0312], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8793, 4.6837, 5.0710, 4.5531]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1293], requires_grad=True)\n","epoch 387, loss 0.13954199850559235\n","epoch 388, loss 0.1386670619249344\n","epoch 389, loss 0.13779795169830322\n","epoch 390, loss 0.1369330883026123\n","epoch 391, loss 0.13607393205165863\n","Parameter containing:\n","tensor([[ 0.9998,  1.6029,  1.2072],\n","        [-0.1245,  1.9553,  1.2608],\n","        [ 1.0887,  2.1716,  0.9587],\n","        [ 1.1608,  2.0181,  0.8403]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4743, 0.5542, 0.0867, 0.0298], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8789, 4.6847, 5.0712, 4.5532]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1276], requires_grad=True)\n","epoch 392, loss 0.1352195292711258\n","epoch 393, loss 0.13437071442604065\n","epoch 394, loss 0.1335262656211853\n","epoch 395, loss 0.13268740475177765\n","epoch 396, loss 0.13185326755046844\n","Parameter containing:\n","tensor([[ 0.9989,  1.6086,  1.2096],\n","        [-0.1322,  1.9564,  1.2658],\n","        [ 1.0901,  2.1767,  0.9593],\n","        [ 1.1624,  2.0232,  0.8409]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4746, 0.5590, 0.0855, 0.0284], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8785, 4.6856, 5.0715, 4.5533]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1259], requires_grad=True)\n","epoch 397, loss 0.13102415204048157\n","epoch 398, loss 0.13019995391368866\n","epoch 399, loss 0.1293805092573166\n","epoch 400, loss 0.1285659670829773\n","epoch 401, loss 0.1277567595243454\n","Parameter containing:\n","tensor([[ 0.9980,  1.6142,  1.2118],\n","        [-0.1397,  1.9574,  1.2706],\n","        [ 1.0915,  2.1819,  0.9599],\n","        [ 1.1639,  2.0282,  0.8414]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4749, 0.5637, 0.0843, 0.0271], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8781, 4.6865, 5.0717, 4.5534]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1242], requires_grad=True)\n","epoch 402, loss 0.12695223093032837\n","epoch 403, loss 0.12615211308002472\n","epoch 404, loss 0.1253577619791031\n","epoch 405, loss 0.1245671734213829\n","epoch 406, loss 0.12378202378749847\n","Parameter containing:\n","tensor([[ 0.9973,  1.6197,  1.2140],\n","        [-0.1471,  1.9585,  1.2753],\n","        [ 1.0929,  2.1869,  0.9605],\n","        [ 1.1654,  2.0332,  0.8418]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4752, 0.5683, 0.0832, 0.0258], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8776, 4.6874, 5.0719, 4.5535]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1224], requires_grad=True)\n","epoch 407, loss 0.1230013519525528\n","epoch 408, loss 0.12222519516944885\n","epoch 409, loss 0.12145410478115082\n","epoch 410, loss 0.12068724632263184\n","epoch 411, loss 0.11992547661066055\n","Parameter containing:\n","tensor([[ 0.9966,  1.6252,  1.2160],\n","        [-0.1543,  1.9597,  1.2799],\n","        [ 1.0943,  2.1919,  0.9610],\n","        [ 1.1669,  2.0381,  0.8423]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4755, 0.5730, 0.0821, 0.0245], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8772, 4.6882, 5.0720, 4.5535]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1206], requires_grad=True)\n","epoch 412, loss 0.11916831880807877\n","epoch 413, loss 0.11841567605733871\n","epoch 414, loss 0.11766770482063293\n","epoch 415, loss 0.1169237345457077\n","epoch 416, loss 0.11618516594171524\n","Parameter containing:\n","tensor([[ 0.9959,  1.6307,  1.2180],\n","        [-0.1614,  1.9608,  1.2844],\n","        [ 1.0957,  2.1968,  0.9614],\n","        [ 1.1684,  2.0429,  0.8426]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4758, 0.5775, 0.0810, 0.0232], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8767, 4.6890, 5.0722, 4.5535]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1188], requires_grad=True)\n","epoch 417, loss 0.1154504120349884\n","epoch 418, loss 0.11472032964229584\n","epoch 419, loss 0.1139947921037674\n","epoch 420, loss 0.11327396333217621\n","epoch 421, loss 0.11255750060081482\n","Parameter containing:\n","tensor([[ 0.9953,  1.6361,  1.2199],\n","        [-0.1684,  1.9620,  1.2888],\n","        [ 1.0971,  2.2017,  0.9619],\n","        [ 1.1699,  2.0477,  0.8430]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4761, 0.5821, 0.0799, 0.0220], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8762, 4.6898, 5.0723, 4.5535]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1169], requires_grad=True)\n","epoch 422, loss 0.11184518784284592\n","epoch 423, loss 0.11113705486059189\n","epoch 424, loss 0.11043347418308258\n","epoch 425, loss 0.10973431915044785\n","epoch 426, loss 0.10903914272785187\n","Parameter containing:\n","tensor([[ 0.9947,  1.6414,  1.2218],\n","        [-0.1752,  1.9632,  1.2931],\n","        [ 1.0985,  2.2064,  0.9623],\n","        [ 1.1714,  2.0524,  0.8433]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4764, 0.5865, 0.0789, 0.0209], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8758, 4.6906, 5.0724, 4.5535]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1150], requires_grad=True)\n","epoch 427, loss 0.10834862291812897\n","epoch 428, loss 0.10766280442476273\n","epoch 429, loss 0.10698045790195465\n","epoch 430, loss 0.10630279034376144\n","epoch 431, loss 0.10562919825315475\n","Parameter containing:\n","tensor([[ 0.9942,  1.6467,  1.2235],\n","        [-0.1819,  1.9645,  1.2973],\n","        [ 1.0999,  2.2112,  0.9627],\n","        [ 1.1729,  2.0570,  0.8436]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4767, 0.5910, 0.0779, 0.0197], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8753, 4.6913, 5.0725, 4.5534]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1131], requires_grad=True)\n","epoch 432, loss 0.10495930910110474\n","epoch 433, loss 0.10429436713457108\n","epoch 434, loss 0.1036328673362732\n","epoch 435, loss 0.10297651588916779\n","epoch 436, loss 0.10232283920049667\n","Parameter containing:\n","tensor([[ 0.9938,  1.6519,  1.2252],\n","        [-0.1885,  1.9658,  1.3014],\n","        [ 1.1013,  2.2158,  0.9630],\n","        [ 1.1744,  2.0615,  0.8439]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4771, 0.5954, 0.0769, 0.0186], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8748, 4.6920, 5.0726, 4.5534]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1112], requires_grad=True)\n","epoch 437, loss 0.10167403519153595\n","epoch 438, loss 0.1010289341211319\n","epoch 439, loss 0.10038800537586212\n","epoch 440, loss 0.09975162148475647\n","epoch 441, loss 0.09911871701478958\n","Parameter containing:\n","tensor([[ 0.9933,  1.6571,  1.2269],\n","        [-0.1950,  1.9670,  1.3054],\n","        [ 1.1026,  2.2204,  0.9633],\n","        [ 1.1758,  2.0660,  0.8441]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4774, 0.5997, 0.0759, 0.0175], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8742, 4.6926, 5.0726, 4.5533]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1093], requires_grad=True)\n","epoch 442, loss 0.09849023073911667\n","epoch 443, loss 0.09786511957645416\n","epoch 444, loss 0.09724393486976624\n","epoch 445, loss 0.09662687033414841\n","epoch 446, loss 0.09601379185914993\n","Parameter containing:\n","tensor([[ 0.9930,  1.6622,  1.2284],\n","        [-0.2013,  1.9684,  1.3093],\n","        [ 1.1040,  2.2249,  0.9636],\n","        [ 1.1773,  2.0704,  0.8443]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4777, 0.6040, 0.0750, 0.0165], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8737, 4.6933, 5.0727, 4.5533]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1074], requires_grad=True)\n","epoch 447, loss 0.0954042598605156\n","epoch 448, loss 0.09479866176843643\n","epoch 449, loss 0.09419699758291245\n","epoch 450, loss 0.09359917044639587\n","epoch 451, loss 0.09300476312637329\n","Parameter containing:\n","tensor([[ 0.9926,  1.6673,  1.2299],\n","        [-0.2075,  1.9697,  1.3131],\n","        [ 1.1053,  2.2293,  0.9638],\n","        [ 1.1787,  2.0748,  0.8445]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4780, 0.6082, 0.0741, 0.0154], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8732, 4.6939, 5.0727, 4.5532]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1054], requires_grad=True)\n","epoch 452, loss 0.09241434186697006\n","epoch 453, loss 0.09182774275541306\n","epoch 454, loss 0.09124496579170227\n","epoch 455, loss 0.09066574275493622\n","epoch 456, loss 0.09008974581956863\n","Parameter containing:\n","tensor([[ 0.9923,  1.6722,  1.2314],\n","        [-0.2136,  1.9710,  1.3168],\n","        [ 1.1067,  2.2337,  0.9641],\n","        [ 1.1801,  2.0791,  0.8447]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4783, 0.6124, 0.0732, 0.0144], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8726, 4.6945, 5.0727, 4.5531]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1035], requires_grad=True)\n","epoch 457, loss 0.08951825648546219\n","epoch 458, loss 0.08894982188940048\n","epoch 459, loss 0.0883849486708641\n","epoch 460, loss 0.08782397210597992\n","epoch 461, loss 0.08726634830236435\n","Parameter containing:\n","tensor([[ 0.9921,  1.6772,  1.2328],\n","        [-0.2196,  1.9724,  1.3205],\n","        [ 1.1080,  2.2380,  0.9643],\n","        [ 1.1815,  2.0833,  0.8448]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4787, 0.6165, 0.0724, 0.0135], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8721, 4.6951, 5.0727, 4.5530]], requires_grad=True)\n","Parameter containing:\n","tensor([6.1015], requires_grad=True)\n","epoch 462, loss 0.08671236783266068\n","epoch 463, loss 0.08616165071725845\n","epoch 464, loss 0.08561483025550842\n","epoch 465, loss 0.08507100492715836\n","epoch 466, loss 0.08453117311000824\n","Parameter containing:\n","tensor([[ 0.9918,  1.6820,  1.2341],\n","        [-0.2255,  1.9738,  1.3240],\n","        [ 1.1093,  2.2422,  0.9645],\n","        [ 1.1829,  2.0874,  0.8450]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4790, 0.6206, 0.0716, 0.0125], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8716, 4.6956, 5.0727, 4.5529]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0996], requires_grad=True)\n","epoch 467, loss 0.08399483561515808\n","epoch 468, loss 0.08346099406480789\n","epoch 469, loss 0.08293146640062332\n","epoch 470, loss 0.08240512013435364\n","epoch 471, loss 0.08188219368457794\n","Parameter containing:\n","tensor([[ 0.9916,  1.6868,  1.2354],\n","        [-0.2313,  1.9751,  1.3275],\n","        [ 1.1106,  2.2464,  0.9646],\n","        [ 1.1843,  2.0915,  0.8451]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4793, 0.6246, 0.0708, 0.0116], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8710, 4.6961, 5.0727, 4.5528]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0977], requires_grad=True)\n","epoch 472, loss 0.08136245608329773\n","epoch 473, loss 0.08084635436534882\n","epoch 474, loss 0.08033290505409241\n","epoch 475, loss 0.07982338219881058\n","epoch 476, loss 0.07931692153215408\n","Parameter containing:\n","tensor([[ 0.9914,  1.6916,  1.2366],\n","        [-0.2369,  1.9765,  1.3309],\n","        [ 1.1119,  2.2505,  0.9648],\n","        [ 1.1857,  2.0955,  0.8452]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4796, 0.6286, 0.0700, 0.0107], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8705, 4.6967, 5.0727, 4.5526]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0957], requires_grad=True)\n","epoch 477, loss 0.07881374657154083\n","epoch 478, loss 0.07831399142742157\n","epoch 479, loss 0.07781706005334854\n","epoch 480, loss 0.07732351869344711\n","epoch 481, loss 0.0768330842256546\n","Parameter containing:\n","tensor([[ 0.9913,  1.6962,  1.2378],\n","        [-0.2425,  1.9779,  1.3342],\n","        [ 1.1132,  2.2545,  0.9649],\n","        [ 1.1870,  2.0994,  0.8452]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4799, 0.6325, 0.0692, 0.0098], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8699, 4.6972, 5.0727, 4.5525]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0938], requires_grad=True)\n","epoch 482, loss 0.07634572684764862\n","epoch 483, loss 0.07586183398962021\n","epoch 484, loss 0.07538089156150818\n","epoch 485, loss 0.07490289956331253\n","epoch 486, loss 0.07442803680896759\n","Parameter containing:\n","tensor([[ 0.9911,  1.7009,  1.2389],\n","        [-0.2479,  1.9794,  1.3375],\n","        [ 1.1144,  2.2585,  0.9650],\n","        [ 1.1883,  2.1033,  0.8453]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4803, 0.6364, 0.0685, 0.0090], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8694, 4.6976, 5.0726, 4.5524]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0919], requires_grad=True)\n","epoch 487, loss 0.07395622879266739\n","epoch 488, loss 0.07348751276731491\n","epoch 489, loss 0.07302192598581314\n","epoch 490, loss 0.07255928963422775\n","epoch 491, loss 0.07209953665733337\n","Parameter containing:\n","tensor([[ 0.9910,  1.7054,  1.2400],\n","        [-0.2533,  1.9808,  1.3407],\n","        [ 1.1157,  2.2624,  0.9651],\n","        [ 1.1896,  2.1071,  0.8454]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4806, 0.6402, 0.0678, 0.0081], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8688, 4.6981, 5.0726, 4.5522]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0899], requires_grad=True)\n","epoch 492, loss 0.07164277136325836\n","epoch 493, loss 0.07118885219097137\n","epoch 494, loss 0.07073833048343658\n","epoch 495, loss 0.07029027491807938\n","epoch 496, loss 0.06984531134366989\n","Parameter containing:\n","tensor([[ 0.9910,  1.7099,  1.2411],\n","        [-0.2585,  1.9822,  1.3438],\n","        [ 1.1169,  2.2662,  0.9652],\n","        [ 1.1909,  2.1109,  0.8454]], requires_grad=True)\n","Parameter containing:\n","tensor([0.4809, 0.6440, 0.0670, 0.0073], requires_grad=True)\n","Parameter containing:\n","tensor([[4.8682, 4.6985, 5.0725, 4.5521]], requires_grad=True)\n","Parameter containing:\n","tensor([6.0880], requires_grad=True)\n","epoch 497, loss 0.06940288841724396\n","epoch 498, loss 0.06896374374628067\n","epoch 499, loss 0.06852717697620392\n","epoch 500, loss 0.06809403747320175\n"],"name":"stdout"}]},{"metadata":{"id":"52f3CdEHT4Y8","colab_type":"text"},"cell_type":"markdown","source":["###Plotting the Loss vs Epochs graph"]},{"metadata":{"ExecuteTime":{"end_time":"2018-10-15T15:21:26.445260Z","start_time":"2018-10-15T15:21:26.282006Z"},"id":"hu6RrNJsmQE6","colab_type":"code","outputId":"8c6ffbba-6b7b-4b98-901e-bf7239fb0596","executionInfo":{"status":"ok","timestamp":1553407105587,"user_tz":-330,"elapsed":1571,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":375}},"cell_type":"code","source":["#Plotting Loss vs Epochs\n","fig,ax = plt.subplots(1)\n","plt.title('Loss vs Epochs')\n","ax.plot(losses)\n","ax.set_ylabel('Loss')\n","ax.set_xlabel('Epoch')\n","plt.savefig('Loss_vs_Epoch.png')"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfIAAAFnCAYAAABdOssgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X9QDh9zqaKsXgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"jP7sVondOXBo","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"metadata":{"id":"OKCEic8hOXs0","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good, But Not Challenging for me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Kq9oZpsLOYBM","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"test'\\\"\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"44DuYN45OYKT","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dXPTTf2XOYRE","colab_type":"code","cellView":"form","outputId":"3bad0194-6854-48ca-d2a6-852b296d1c3f","executionInfo":{"status":"ok","timestamp":1553407106913,"user_tz":-330,"elapsed":1127,"user":{"displayName":"Priyanka Reballi","photoUrl":"https://lh3.googleusercontent.com/-V6_LdSfo-Mg/AAAAAAAAAAI/AAAAAAAAAAc/14459E2SOuE/s64/photo.jpg","userId":"09098537642923167382"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Your submission is successful.\n","Ref Id: 21356\n","Date of submission:  24 Mar 2019\n","Time of submission:  11:25:59\n","View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\n","For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\n"],"name":"stdout"}]}]}