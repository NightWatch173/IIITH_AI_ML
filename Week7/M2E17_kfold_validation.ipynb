{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M2E17_kfold_validation.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"EjcpcKwppPJC","colab_type":"text"},"cell_type":"markdown","source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"metadata":{"id":"ksg-aNjbn2h0","colab_type":"text"},"cell_type":"markdown","source":["## Learning Objectives"]},{"metadata":{"id":"dW2P6nr1n6fv","colab_type":"text"},"cell_type":"markdown","source":["At the end of the experiment, you will be able to:\n","\n","\n","*  Apply K-Fold cross validation method \n","*  Tune the hyper parameters of MLP Classifier."]},{"metadata":{"id":"A9Gi0Ofj6h_9","colab_type":"code","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":322},"outputId":"389b32ca-dfb6-4970-c840-bdbd22719a2b","executionInfo":{"status":"ok","timestamp":1556339608783,"user_tz":-330,"elapsed":1127,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"cell_type":"code","source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"500\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/aiml/AIML_BATCH_HYD_7/23FEB/module_2_week_8_experment_5.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"500\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/aiml/AIML_BATCH_HYD_7/23FEB/module_2_week_8_experment_5.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"ovdZ_4tln7Oz","colab_type":"text"},"cell_type":"markdown","source":["## Dataset"]},{"metadata":{"id":"ZbclXs06n8-b","colab_type":"text"},"cell_type":"markdown","source":["### Description:\n","\n","The MNIST dataset contains: \n","\n","1. 60,000 Handwritten digits as training samples and 10,000 Test samples, \n","which means each digit occurs 6000 times in the training set and 1000 times in the testing set. (approximately). \n","2. Each image is Size Normalized and Centered \n","3. Each image is 28 X 28 Pixel with 0-255 Gray Scale Value. \n","4. That means each image is represented as 784 (28 X28) dimension vector where each value is in the range 0- 255.\n","\n","\n","\n","### History\n","\n","Yann LeCun (Director of AI Research, Facebook, Courant Institute, NYU) was given the task of identifying the cheque numbers (in the 90’s) and the amount associated with that cheque without manual intervention. That is when this dataset was created which raised the bars and became a benchmark.\n","\n","Yann LeCun and Corinna Cortes (Google Labs, New York) hold the copyright of MNIST dataset, which is a subset of the original NIST datasets. This dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license. \n","\n","It is the handwritten digits dataset in which half of them are written by the Census Bureau employees and remaining by the high school students. The digits collected among the Census Bureau employees are easier and cleaner to recognize than the digits collected among the students.\n","\n","\n","### Challenges\n","\n","Now, if you notice the images below, you will find that between 2 characters there are always certain similarities and differences. To teach a machine to recognize these patterns and identify the correct output.\n","\n","![altxt](https://www.researchgate.net/profile/Radu_Tudor_Ionescu/publication/282924675/figure/fig3/AS:319968869666820@1453297931093/A-random-sample-of-6-handwritten-digits-from-the-MNIST-data-set-before-and-after.png)\n","\n","Hence, all these challenges make this a good problem to solve in Machine Learning.\n"]},{"metadata":{"id":"ZkLmftP9oCeD","colab_type":"text"},"cell_type":"markdown","source":["## Domain Information"]},{"metadata":{"id":"M2LBE8FOoGrF","colab_type":"text"},"cell_type":"markdown","source":["Handwriting changes person to person. Some of us have neat handwriting and some have illegible handwriting such as doctors. However, if you think about it even a child who recognizes alphabets and numerics can identify the characters of a text even written by a stranger. But even a technically knowledgeable adult cannot describe the process by which he or she recognizes the text/letters. As you know this is an excellent challenge for Machine Learning.\n","\n","![altxt](https://i.pinimg.com/originals/f2/7a/ac/f27aac4542c0090872110836d65f4c99.jpg)\n"]},{"metadata":{"id":"AbwQ87pLoMAr","colab_type":"text"},"cell_type":"markdown","source":["## AI /ML Technique"]},{"metadata":{"id":"old2jD8doO0T","colab_type":"text"},"cell_type":"markdown","source":["### K-Fold Cross Validation\n","\n","\n","The problem with machine learning models is that you won’t get to know how well a model performs until you test it's performance on an independent data set (the data set which was not used for training the machine learning model).\n","\n","Cross Validation comes in to picture here and helps us to estimate the performance of our model. One type of cross validation is the K-Fold Cross Validation\n","\n","In our experiment we are using K-Fold Cross Validation  technique to reduce (limit) the problem of overfitting. K-Fold Cross Validation is way to evaluate and improve the performance of our machine learning model. It helps preventing from overfitting to a single train or test split. \n","\n","\n","When we are given a machine learning problem,we will be given two type of data sets — known data (training data set) and unknown data (test data set). By using cross validation, you would be “testing” your machine learning model in the “training” phase to check for overfitting and to get an idea about how your machine learning model will generalize to independent data, which is the test data set given in the problem.\n","\n","\n","In first round of cross validation, we have to divide our original training data set into two parts:\n","\n","1. Cross validation training set\n","2. Cross validation testing set or Validation set\n","\n","![alt text](https://cdn.talentsprint.com/aiml/Experiment_related_data/IMAGES/K-Fold.png)\n","\n","The above image represents how the K-Fold Cross Validation works. We divide the dataset in to \"K'' parts and will use the K-1 parts for training and remaining 1 for testing. We will rotate the test set and repeat the process for \"K\" times. \n","\n","we will train our machine learning model on the cross validation training set and test the model’s predictions against the validation set. we will get to know how accurate our machine learning model’s predictions are when we compare the model’s predictions on the validation set and the actual labels of the data points in the validation set.\n","\n","To reduce the variability, multiple rounds of cross validation are performed by using different cross validation training sets and cross validation testing sets. The results from all the rounds are averaged to estimate the accuracy of the machine learning model.\n","\n","**K-fold cross validation is performed as per the following steps:**\n","\n","1. Randomly split entire training dataset into k subsets.\n","2. Reserve one block as our test data\n","3. Train on each of the remaining K-1 blocks\n","4. Measure the performance against the test set\n","5. The average of our K recorded errors is called the cross-validation error and it will be used as performance metric for the model\n","\n","For this particular experiment we have applied k-foldclassifier() from sklearn.\n"]},{"metadata":{"id":"883iWwdPpyth","colab_type":"text"},"cell_type":"markdown","source":["#### Expected time : 30mins"]},{"metadata":{"id":"tQvkNNTfpS2T","colab_type":"text"},"cell_type":"markdown","source":["### Setup Steps"]},{"metadata":{"id":"sv8x78fVpU3M","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P181902118\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mG6_CNdepXHW","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"8860303743\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"91nkI1fp_SLR","colab_type":"code","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b2b45d1e-f566-4e43-b4e2-f17143efcc10","executionInfo":{"status":"ok","timestamp":1556339798158,"user_tz":-330,"elapsed":1465,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"cell_type":"code","source":["#@title Run this cell to complete the setup for this Notebook  \n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M2W6E17_kfold_validation\" #name of the notebook\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")  \n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      print(\"Your submission is successful.\")\n","      print(\"Ref Id:\", submission_id)\n","      print(\"Date of submission: \", r[\"date\"])\n","      print(\"Time of submission: \", r[\"time\"])\n","      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n","      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","\n","  if submission_id:\n","    setup()\n","\n","    from IPython.display import HTML\n","    HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id))\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=P181902118&recordId=4219\"></script>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"metadata":{"id":"SFzKqwLppPJI","colab_type":"code","colab":{}},"cell_type":"code","source":["## Importing required packages\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zWoLTkutpPJN","colab_type":"text"},"cell_type":"markdown","source":["Loading the dataset from sklearn package"]},{"metadata":{"id":"d3Zg9n4zpPJO","colab_type":"code","colab":{}},"cell_type":"code","source":["## Loading MNIST dataset from sklearn\n","digits = datasets.load_digits(n_class=10)\n","## Loding the data and storing in x\n","X = digits.data\n","## Loading the target data and storing it in y\n","y = digits.target"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GKvy1plDpPJS","colab_type":"code","colab":{}},"cell_type":"code","source":["### hyper parameters\n","# activation\n","a = [\"identity\",\"logistic\",\"tanh\",\"relu\"]\n","#solvers\n","s = [\"lbfgs\",\"sgd\",\"adam\"]\n","#learning rate\n","lr = [0.0001,0.001,0.01,0.1]\n","#hidden layers\n","h = [(5,2),(3,2),(6,3),(7,2)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FKanYk0rpPJW","colab_type":"code","colab":{}},"cell_type":"code","source":["## Applying K-Folds cross-validator\n","kf = KFold(n_splits=4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DqWhE0sspPJd","colab_type":"code","colab":{}},"cell_type":"code","source":["#function to Create MLP classifier object with hyper parameters\n","def mlp(a,s,h,lr):\n","    clf = MLPClassifier(activation= a ,solver= s ,hidden_layer_sizes = h,learning_rate_init=lr)\n","    return clf  \n","#function to calculate the accuracy\n","def accuracy(actual,predicted):\n","    return accuracy_score(actual,predicted)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FYi1hdOIOiq-","colab_type":"text"},"cell_type":"markdown","source":["#### Calculating Training and Testing accuracies"]},{"metadata":{"id":"TYeKG-copPJl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1799},"outputId":"2d71ce23-6b18-4315-a0de-6158c39ee057","executionInfo":{"status":"ok","timestamp":1556339833023,"user_tz":-330,"elapsed":24455,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"cell_type":"code","source":["test_accuracy = []\n","train_accuracy = []\n","for i in range(10):\n","    k1 = np.random.randint(0,len(a))\n","    k2 = np.random.randint(0,len(s))\n","    k3 = np.random.randint(0,len(lr))\n","    k4 = np.random.randint(0,len(h))\n","    print(\"\\nHyper-parameters = \\n activation = \", a[k1],    \"\\n solver = \", s[k2], \"\\n learning_rate_init = \", lr[k3],         \"\\n hidden_layer_sizes = \", h[k4])\n","     #calling the mlp function with random hyper paramters\n","    clf = mlp(a[k1],s[k2],h[k4],lr[k3])\n","    tempTrain = 0\n","    tempTest = 0\n","    for nbrOfFolds,(train_index, test_index) in enumerate(kf.split(X)):\n","        ## Splitting the data into train and test\n","        X_train, X_test = X[train_index], X[test_index]\n","        Y_train, Y_test  = y[train_index], y[test_index]\n","        ##fit the data into the model\n","        clf.fit(X_train,Y_train)\n","        ##predicting the values on the fitted model using train data\n","        predTrain = clf.predict((X_train))\n","        #adding the accuracy\n","        tempTrain = tempTrain + accuracy(Y_train,predTrain)\n","        ##predict the values on the fitted model using test data\n","        predTest = clf.predict((X_test))\n","        #adding the accuracy\n","        tempTest = tempTest + accuracy(Y_test,predTest)\n","    ##Calculating the train accuracy\n","    print(f'Number of folds is{nbrOfFolds+1}')\n","    train_accuracy.append(tempTrain*1.0/(nbrOfFolds+1))\n","    ##Calculating the test accuracy\n","    test_accuracy.append(tempTest*1.0/4)\n","    print(\"(train,test) accuracy = \",tempTrain*1.0/4, tempTest*1.0/4)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\n","Hyper-parameters = \n"," activation =  tanh \n"," solver =  sgd \n"," learning_rate_init =  0.0001 \n"," hidden_layer_sizes =  (7, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of folds is4\n","(train,test) accuracy =  0.1704732078539187 0.1546832467211086\n","\n","Hyper-parameters = \n"," activation =  identity \n"," solver =  lbfgs \n"," learning_rate_init =  0.0001 \n"," hidden_layer_sizes =  (7, 2)\n","Number of folds is4\n","(train,test) accuracy =  0.7805597227821359 0.7050408314773571\n","\n","Hyper-parameters = \n"," activation =  identity \n"," solver =  adam \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (7, 2)\n","Number of folds is4\n","(train,test) accuracy =  0.7681344574931874 0.6839086859688196\n","\n","Hyper-parameters = \n"," activation =  tanh \n"," solver =  adam \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (7, 2)\n","Number of folds is4\n","(train,test) accuracy =  0.2765824538098731 0.24929349170997278\n","\n","Hyper-parameters = \n"," activation =  logistic \n"," solver =  adam \n"," learning_rate_init =  0.001 \n"," hidden_layer_sizes =  (6, 3)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of folds is4\n","(train,test) accuracy =  0.40199440343306037 0.3744295966344964\n","\n","Hyper-parameters = \n"," activation =  identity \n"," solver =  sgd \n"," learning_rate_init =  0.01 \n"," hidden_layer_sizes =  (3, 2)\n","Number of folds is4\n","(train,test) accuracy =  0.7516213632228119 0.6788864142538975\n","\n","Hyper-parameters = \n"," activation =  logistic \n"," solver =  lbfgs \n"," learning_rate_init =  0.01 \n"," hidden_layer_sizes =  (6, 3)\n","Number of folds is4\n","(train,test) accuracy =  0.5314020716439873 0.4936896807720861\n","\n","Hyper-parameters = \n"," activation =  relu \n"," solver =  sgd \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (5, 2)\n","Number of folds is4\n","(train,test) accuracy =  0.10202210539301536 0.09738678544914625\n","\n","Hyper-parameters = \n"," activation =  relu \n"," solver =  sgd \n"," learning_rate_init =  0.001 \n"," hidden_layer_sizes =  (3, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of folds is4\n","(train,test) accuracy =  0.28217034667653584 0.2564464241524375\n","\n","Hyper-parameters = \n"," activation =  relu \n"," solver =  lbfgs \n"," learning_rate_init =  0.01 \n"," hidden_layer_sizes =  (5, 2)\n","Number of folds is4\n","(train,test) accuracy =  0.31108240864962033 0.30716035634743877\n"],"name":"stdout"}]},{"metadata":{"id":"6baqLI7VpPJr","colab_type":"text"},"cell_type":"markdown","source":["#### Plotting the data"]},{"metadata":{"id":"Z_CMEv2apPJt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"e9356281-8948-4a87-b597-b59decc5c5e1","executionInfo":{"status":"ok","timestamp":1556339834365,"user_tz":-330,"elapsed":24800,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"cell_type":"code","source":["##Plotting the data\n","xx = np.array(range(1,11))\n","plt.bar(xx-0.2,train_accuracy,width=0.2)\n","plt.bar(xx, test_accuracy,width=0.2)\n","plt.legend([\"Train\",\"Test\"])\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"skiIgURmpPJx","colab_type":"text"},"cell_type":"markdown","source":["#### Ungraded Exercise \n","\n","Vary the number of k-fold splits and observe the changes"]},{"metadata":{"id":"677BLEdKQ_Mg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1982},"outputId":"6013e091-f241-4b0f-e1ed-75197a1e3d60","executionInfo":{"status":"ok","timestamp":1556341164137,"user_tz":-330,"elapsed":39553,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"cell_type":"code","source":["### Your code here\n","\n","kf = KFold(n_splits=7)\n","\n","\n","#function to Create MLP classifier object with hyper parameters\n","def mlp(a,s,h,lr):\n","    clf = MLPClassifier(activation= a ,solver= s ,hidden_layer_sizes = h,learning_rate_init=lr)\n","    return clf  \n","#function to calculate the accuracy\n","def accuracy(actual,predicted):\n","    return accuracy_score(actual,predicted)\n","  \n","test_accuracy = []\n","train_accuracy = []\n","for i in range(10):\n","    k1 = np.random.randint(0,len(a))\n","    k2 = np.random.randint(0,len(s))\n","    k3 = np.random.randint(0,len(lr))\n","    k4 = np.random.randint(0,len(h))\n","    print(\"\\nHyper-parameters = \\n activation = \", a[k1],    \"\\n solver = \", s[k2], \"\\n learning_rate_init = \", lr[k3],         \"\\n hidden_layer_sizes = \", h[k4])\n","     #calling the mlp function with random hyper paramters\n","    clf = mlp(a[k1],s[k2],h[k4],lr[k3])\n","    tempTrain = 0\n","    tempTest = 0\n","    for nbrOfFolds,(train_index, test_index) in enumerate(kf.split(X)):\n","        ## Splitting the data into train and test\n","        X_train, X_test = X[train_index], X[test_index]\n","        Y_train, Y_test  = y[train_index], y[test_index]\n","        ##fit the data into the model\n","        clf.fit(X_train,Y_train)\n","        ##predicting the values on the fitted model using train data\n","        predTrain = clf.predict((X_train))\n","        #adding the accuracy\n","        tempTrain = tempTrain + accuracy(Y_train,predTrain)\n","        ##predict the values on the fitted model using test data\n","        predTest = clf.predict((X_test))\n","        #adding the accuracy\n","        tempTest = tempTest + accuracy(Y_test,predTest)\n","    ##Calculating the train accuracy\n","    print(f'Number of folds is{nbrOfFolds+1}')\n","    train_accuracy.append(tempTrain*1.0/(nbrOfFolds+1))\n","    ##Calculating the test accuracy\n","    test_accuracy.append(tempTest*1.0/4)\n","    print(\"(train,test) accuracy = \",tempTrain*1.0/4, tempTest*1.0/4)\n","\n","##Plotting the data\n","xx = np.array(range(1,11))\n","plt.bar(xx-0.2,train_accuracy,width=0.2)\n","plt.bar(xx, test_accuracy,width=0.2)\n","plt.legend([\"Train\",\"Test\"])\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["\n","Hyper-parameters = \n"," activation =  tanh \n"," solver =  sgd \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (6, 3)\n","Number of folds is7\n","(train,test) accuracy =  1.2807909562857647 1.1918774319066148\n","\n","Hyper-parameters = \n"," activation =  identity \n"," solver =  adam \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (6, 3)\n","Number of folds is7\n","(train,test) accuracy =  1.5901282688758354 1.416923790126459\n","\n","Hyper-parameters = \n"," activation =  relu \n"," solver =  adam \n"," learning_rate_init =  0.01 \n"," hidden_layer_sizes =  (6, 3)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of folds is7\n","(train,test) accuracy =  0.6398045416621017 0.5503252675097277\n","\n","Hyper-parameters = \n"," activation =  identity \n"," solver =  adam \n"," learning_rate_init =  0.01 \n"," hidden_layer_sizes =  (3, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of folds is7\n","(train,test) accuracy =  1.3590065272171048 1.2250995561770428\n","\n","Hyper-parameters = \n"," activation =  tanh \n"," solver =  lbfgs \n"," learning_rate_init =  0.001 \n"," hidden_layer_sizes =  (3, 2)\n","Number of folds is7\n","(train,test) accuracy =  0.5620641850038346 0.5132576909046692\n","\n","Hyper-parameters = \n"," activation =  tanh \n"," solver =  adam \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (7, 2)\n","Number of folds is7\n","(train,test) accuracy =  0.6192061993814104 0.5881756140564203\n","\n","Hyper-parameters = \n"," activation =  relu \n"," solver =  adam \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (5, 2)\n","Number of folds is7\n","(train,test) accuracy =  0.19931841357863422 0.2035087852626459\n","\n","Hyper-parameters = \n"," activation =  logistic \n"," solver =  sgd \n"," learning_rate_init =  0.0001 \n"," hidden_layer_sizes =  (7, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of folds is7\n","(train,test) accuracy =  0.16798650732784412 0.16362171692607003\n","\n","Hyper-parameters = \n"," activation =  identity \n"," solver =  sgd \n"," learning_rate_init =  0.01 \n"," hidden_layer_sizes =  (6, 3)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n","  tmp = X - X.max(axis=1)[:, np.newaxis]\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of folds is7\n","(train,test) accuracy =  1.3721108952695584 1.2271970756322959\n","\n","Hyper-parameters = \n"," activation =  tanh \n"," solver =  adam \n"," learning_rate_init =  0.01 \n"," hidden_layer_sizes =  (5, 2)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Number of folds is7\n","(train,test) accuracy =  1.081269225582983 1.0099784168287937\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuEtSgf4fdvAi12lNDgUAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"rgymX3hOphVj","colab_type":"text"},"cell_type":"markdown","source":["### Please answer the questions below to complete the experiment:"]},{"metadata":{"id":"HwlIHH_nQBAE","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title K-fold cross validation helps with overcoming overfitting problem? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer=\"TRUE\" #@param[\"TRUE\",\"FALSE\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZUD27jBgpPJz","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good and Challenging me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KJw1jBtxplns","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dbgppxZ1pnTD","colab_type":"code","colab":{}},"cell_type":"code","source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"97hl2G5Ipoyd","colab_type":"code","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"870cb4fc-d118-45f7-dfcb-695315b1180c","executionInfo":{"status":"ok","timestamp":1556341739156,"user_tz":-330,"elapsed":1468,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"cell_type":"code","source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Your submission is successful.\n","Ref Id: 4219\n","Date of submission:  27 Apr 2019\n","Time of submission:  10:36:28\n","View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\n","For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\n"],"name":"stdout"}]}]}