{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M3E37_Uniform_Nonuniform_Quantization.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0SI_AEBcqs_S","colab_type":"text"},"source":["\n","# Advanced Certification in AIML\n","## A Program by IIIT-H and TalentSprint"]},{"cell_type":"markdown","metadata":{"id":"tR1wvEVM6fTG","colab_type":"text"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"vESOoKZe7DBx","colab_type":"text"},"source":["At the end of the experiment, you will be able to:\n","\n","\n","* Classify the MNIST dataset using MLP and then quantize the weights of the network \n","* Understand how quantization reduces the storage needs of the network"]},{"cell_type":"code","metadata":{"id":"lfk8109wnqAl","colab_type":"code","cellView":"form","outputId":"9420d901-52a2-4eb8-d916-1f2ad1b1f772","executionInfo":{"status":"ok","timestamp":1558852244080,"user_tz":-330,"elapsed":855,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}},"colab":{"base_uri":"https://localhost:8080/","height":322}},"source":["#@title Experiment Explanation Video\n","from IPython.display import HTML\n","\n","HTML(\"\"\"<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/aiml/AIML_BATCH_HYD_7/March31/uniform_nonuniform_quantization.mp4\" type=\"video/mp4\">\n","</video>\n","\"\"\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<video width=\"800\" height=\"300\" controls>\n","  <source src=\"https://cdn.talentsprint.com/aiml/AIML_BATCH_HYD_7/March31/uniform_nonuniform_quantization.mp4\" type=\"video/mp4\">\n","</video>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"o3b5-r1S7Fkh","colab_type":"text"},"source":["## Dataset"]},{"cell_type":"markdown","metadata":{"id":"tIcN-gMa7KOW","colab_type":"text"},"source":["\n","###Description\n","\n","\n","1. The dataset contains 60,000 Handwritten digits as training samples and 10,000 Test samples, which means each digit occurs 6000 times in the training set and 1000 times in the testing set (approximately). \n","2. Each image is Size Normalized and Centered. \n","3. Each image is 28 X 28 Pixel with 0-255 Gray Scale Value. \n","4. That means each image is represented as 784 (28 X28) dimension vector where each value is in the range 0- 255.\n","\n","###History\n","\n","Yann LeCun (Director of AI Research, Facebook, Courant Institute, NYU) was given the task of identifying the cheque numbers (in the 90â€™s) and the amount associated with that cheque without manual intervention. That is when this dataset was created which raised the bars and became a benchmark.\n","\n","Yann LeCun and Corinna Cortes (Google Labs, New York) hold the copyright of MNIST dataset, which is a subset of the original NIST datasets. This dataset is made available under the terms of the Creative Commons Attribution-Share Alike 3.0 license. \n","\n","It is the handwritten digits dataset in which half of them are written by the Census Bureau employees and remaining by the high school students. The digits collected among the Census Bureau employees are easier and cleaner to recognize than the digits collected among the students.\n","\n","\n","###Challenges\n","\n","Now, if you notice the images below, you will find that between 2 characters there are always certain similarities and differences. To teach a machine to recognize these patterns and identify the correct output is intriguing.\n","\n","![altxt](https://www.researchgate.net/profile/Radu_Tudor_Ionescu/publication/282924675/figure/fig3/AS:319968869666820@1453297931093/A-random-sample-of-6-handwritten-digits-from-the-MNIST-data-set-before-and-after.png)\n","\n","Hence, all these challenges make this a good problem to solve in Machine Learning."]},{"cell_type":"markdown","metadata":{"id":"mrRu_oSI7MLm","colab_type":"text"},"source":["## Domain Information"]},{"cell_type":"markdown","metadata":{"id":"OZJqmAkO7Qm2","colab_type":"text"},"source":["Handwriting changes person to person. Some of us have neat handwriting and some have illegible handwriting such as doctors. However, if you think about it even a child who recognizes alphabets and numerics can identify the characters of a text even written by a stranger. But even a technically knowledgeable adult cannot describe the process by which he or she recognizes the text/letters. As you know this is an excellent challenge for Machine Learning.\n","\n","![altxt](https://i.pinimg.com/originals/f2/7a/ac/f27aac4542c0090872110836d65f4c99.jpg)\n","\n","The experiment handles a subset of text recognition, namely recognizing the 10 numerals (0 to 9) from scanned images.\n"]},{"cell_type":"markdown","metadata":{"id":"W_onQyDA7Uoc","colab_type":"text"},"source":["## AI / ML Technique"]},{"cell_type":"markdown","metadata":{"id":"Qb2Jfqj67XEr","colab_type":"text"},"source":["### Quantization for Image Classification:\n","\n","In this experiment, we train a neural network on the dataset to classify the images and then reduce the storage requirements of the network by quantizing the weights of the network using compression.\n","\n","Neural network models can take up a lot of space on disk where almost all of that space is taken up by the weights of the neural connections, which are often millions in number in a single model. As the weights arer all slightly different floating point numbers, simple compression formats like zip don't compress them well. Quantization is a network compression technique that is used to save the storage for the many parameters of the network by compressing the weights. The weights intially are represented as 8-bit values, so we are using 2 * 8 = 16 in storage. If we are compressing the weights to 1-bit values, we are storing only 1 * 8 = 8 in storage thus reducing our storage needs by half.  Depending on how the weight space is distributed into clusters, there are two types of quantization techniques:\n","\n","1. **Uniform Quantization**: The cluster heads are uniformly spaced.\n","2. **Non-uniform Quantization**:  The cluster heads are non - uniformly spaced using K - Means clustering.\n"," \n","You will understand these in detail while working on the code in the experiment. "]},{"cell_type":"markdown","metadata":{"id":"TCMtDHSHqs_W","colab_type":"text"},"source":["## Keywords\n","\n","* Uniform quantization\n","* Non-uniform quantization\n","* K-means clustering\n"]},{"cell_type":"markdown","metadata":{"id":"u2vKGcIvqs_Y","colab_type":"text"},"source":["### Expected time to complete the experiment is : 90 min"]},{"cell_type":"markdown","metadata":{"id":"P8C30f_7qy9u","colab_type":"text"},"source":["### Setup Steps"]},{"cell_type":"code","metadata":{"id":"tcCyG_oJq0oi","colab_type":"code","colab":{}},"source":["#@title Please enter your registration id to start: (e.g. P181900101) { run: \"auto\", display-mode: \"form\" }\n","Id = \"P181902118\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KxGcskFTq28t","colab_type":"code","colab":{}},"source":["#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"8860303743\" #@param {type:\"string\"}\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHnOie0kirKu","colab_type":"code","cellView":"form","outputId":"7f4d32f5-6a16-4260-f33c-479337cb5b66","executionInfo":{"status":"ok","timestamp":1558977596936,"user_tz":-330,"elapsed":8568,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","  \n","notebook=\"BLR_M3W2E37_Uniform_Nonuniform_Quantization\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")  \n","    ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx pip3 install torchvision\")\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    \n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","    \n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:        \n","        print(r[\"err\"])\n","        return None        \n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n","              \"concepts\" : Concepts, \"record_id\" : submission_id, \n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook}\n","\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      print(\"Your submission is successful.\")\n","      print(\"Ref Id:\", submission_id)\n","      print(\"Date of submission: \", r[\"date\"])\n","      print(\"Time of submission: \", r[\"time\"])\n","      print(\"View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\")\n","      print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","      return submission_id\n","    else: submission_id\n","    \n","\n","def getAdditional():\n","  try:\n","    if Additional: return Additional      \n","    else: raise NameError('')\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","  \n","def getConcepts():\n","  try:\n","    return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","def getId():\n","  try: \n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup \n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","    from IPython.display import HTML\n","    HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id))\n","  \n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"],"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/html":["<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=P181902118&recordId=5649\"></script>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Setup completed successfully\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LX6ALkaHqs_Y","colab_type":"text"},"source":["Once again we do our regular imports."]},{"cell_type":"code","metadata":{"id":"Mk4-H3VnNSBi","colab_type":"code","colab":{}},"source":["import numpy as np\n","np.random.seed(1337)  # for reproducibility\n","from sklearn.cluster import KMeans\n","import torch \n","import torchvision\n","import torch.nn as nn\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","\n","from torch.autograd import Variable\n","%matplotlib inline\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-dE4fUykNSBm","colab_type":"text"},"source":["### Hyperparameters"]},{"cell_type":"code","metadata":{"id":"FKpyM4zzNSBm","colab_type":"code","colab":{}},"source":["num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001\n","use_reg = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9E-00Slqs_k","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mJH3yYJKNSBp","colab_type":"text"},"source":["### Downloading the MNIST dataset"]},{"cell_type":"code","metadata":{"id":"3inDH-alNSBq","colab_type":"code","outputId":"de8f1928-821e-43ee-bb5b-1f6646e51e81","executionInfo":{"status":"ok","timestamp":1558976713786,"user_tz":-330,"elapsed":2154,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["train_dataset = dsets.MNIST(root='../data/',\n","                            train=True, \n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='../data/',\n","                           train=False, \n","                           transform=transforms.ToTensor())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["  0%|          | 0/9912422 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["9920512it [00:00, 27046523.65it/s]                            \n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["32768it [00:00, 446907.99it/s]\n","  1%|          | 16384/1648877 [00:00<00:11, 142643.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["1654784it [00:00, 7463163.21it/s]                           \n","8192it [00:00, 180335.79it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3cIqGefQNSBw","colab_type":"text"},"source":["### Dataloader"]},{"cell_type":"code","metadata":{"id":"_3Nxm0bXNSBw","colab_type":"code","colab":{}},"source":["train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MrX-dz4fNSB1","colab_type":"text"},"source":["### Define the network"]},{"cell_type":"code","metadata":{"id":"DYXjWlJsNSB2","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU())\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2))\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2))\n","        self.fc1 = nn.Linear(7*7*32, 300)\n","        self.fc2 = nn.Linear(300, 10)\n","        \n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.fc1(out)\n","        out = self.fc2(out)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ne2DrrXiNSB5","colab_type":"text"},"source":["<b>The below function is called to reinitialize the weights of the network and define the required loss criterion and the optimizer.</b> "]},{"cell_type":"code","metadata":{"id":"7ui3ChcWNSB6","colab_type":"code","colab":{}},"source":["def reset_model():\n","    net = Net()\n","    net = net.to(device)\n","\n","    # Loss and Optimizer\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","    return net,criterion,optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EfBSn8rJNSB8","colab_type":"text"},"source":["### Initializing the model"]},{"cell_type":"code","metadata":{"id":"7vLzLbbnNSB9","colab_type":"code","colab":{}},"source":["net, criterion, optimizer = reset_model()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZyXY7Oq6NSCB","colab_type":"text"},"source":["### Defining a L1 Regularizer"]},{"cell_type":"code","metadata":{"id":"zMLxnmDkNSCC","colab_type":"code","colab":{}},"source":["def l1_regularizer(net, loss, beta):\n","    l1_crit = nn.L1Loss(size_average=False)\n","    reg_loss = 0\n","    for param in net.parameters():\n","        target = (torch.FloatTensor(param.size()).zero_()).to(device)\n","        reg_loss += l1_crit(param, target)\n","        \n","    loss += beta * reg_loss\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3NogS9pZNSCF","colab_type":"text"},"source":["### Training function"]},{"cell_type":"code","metadata":{"id":"6hUX_GntNSCG","colab_type":"code","colab":{}},"source":["# Train the Model\n","\n","def training(net, reset = True):\n","    if reset == True:\n","        net, criterion, optimizer = reset_model()\n","    else:\n","        criterion = nn.CrossEntropyLoss()\n","        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","    \n","    net.train()\n","    for epoch in range(num_epochs):\n","        total_loss = 0\n","        accuracy = []\n","        for i, (images, labels) in enumerate(train_loader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            temp_labels = labels\n","          \n","\n","            # Forward + Backward + Optimize\n","            optimizer.zero_grad()\n","            outputs = net(images)\n","            loss = criterion(outputs, labels)\n","\n","            if use_reg == True :\n","                loss = l1_regularizer(net,loss,beta=0.001)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            correct = (predicted == temp_labels).sum().item()\n","            accuracy.append(correct/float(batch_size))\n","\n","        print('Epoch: %d, Loss: %.4f, Accuracy: %.4f' %(epoch+1,total_loss, (sum(accuracy)/float(len(accuracy)))))\n","    \n","    return net"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_5fha93LNSCI","colab_type":"text"},"source":["### Testing function"]},{"cell_type":"code","metadata":{"id":"Kj1AAWuBNSCL","colab_type":"code","colab":{}},"source":["# Test the Model\n","def testing(net):\n","    net.eval() \n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","       \n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    print('Test Accuracy of the network on the 10000 test images: %.2f %%' % (100.0 * correct / total))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T4WRXM1YNSCP","colab_type":"text"},"source":["### Training and testing the network"]},{"cell_type":"code","metadata":{"id":"qSfX2-vFNSCP","colab_type":"code","outputId":"d7cae683-e8f0-4d89-ee3c-3886673aa292","executionInfo":{"status":"ok","timestamp":1558976807557,"user_tz":-330,"elapsed":59799,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}},"colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["reset = False\n","net = training(net, reset)\n","testing(net)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1, Loss: 535.3272, Accuracy: 0.9543\n","Epoch: 2, Loss: 235.3397, Accuracy: 0.9765\n","Epoch: 3, Loss: 187.6216, Accuracy: 0.9798\n","Epoch: 4, Loss: 167.9835, Accuracy: 0.9811\n","Epoch: 5, Loss: 158.0960, Accuracy: 0.9819\n","Test Accuracy of the network on the 10000 test images: 98.17 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b8kc_CbbNSCR","colab_type":"text"},"source":["### Uniform Quantization\n","\n","The simplest motivation for quantization is to shrink file sizes by storing the min and max for each layer, and then compressing each float value to an eight-bit integer representing the closest real number in a linear set of 256 within the range.\n","\n","In the function below we send 8 bits as input which ressembles that the weights of the network should be represented with only 8 bits while storing to disk. In other words we use only 2^8 or 256 clusters. Hence each weight is represented as a 8-bit integer between 0-255.\n","\n","Thus before using the weights during test time they need to be projected into the original weight space by using the following equation:\n","\n","$$\n","W_{i} = min + \\dfrac{max-min}{255}*W_{index}\n","$$"]},{"cell_type":"code","metadata":{"id":"bkD7PGOCNSCT","colab_type":"code","colab":{}},"source":["def uniform_quantize(weight, bits):\n","    print('-------------------------LAYER---------------------------')\n","    print(\"Number of unique parameters before quantization: \" + str(len(np.unique(weight))))\n","    n_clusters = 2**bits\n","    \n","    maxim = np.amax(weight)\n","    minim = np.amin(weight)\n","    step= (maxim-minim)/(n_clusters - 1)\n","\n","    clusters=[]\n","\n","    for i in range(0,n_clusters):\n","        clusters.append(minim)\n","        minim+=step\n","\n","    for i in range(0,len(weight)):\n","        dist= (clusters-weight[i])**2     \n","        weight[i]=clusters[np.argmin(dist)]\n","        \n","    print(\"Number of unique parameters after quantization: \" + str(len(np.unique(weight))))\n","    \n","    return weight  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NWEIuI9wNSCU","colab_type":"text"},"source":["### Uniform Quantization\n","\n","Different number of bits can be used for representing the weights and biases. The exact number of bits to use is a design choice and may depend on the complexity of the task at hand since using too less number of bits can result in poor performance. Here, we use 8 bits for quantizing the weights and 1 bit for the biases."]},{"cell_type":"code","metadata":{"id":"JpJ1C75qNSCU","colab_type":"code","outputId":"d6e6b6ff-72a5-472f-9289-08c064dc575f","executionInfo":{"status":"ok","timestamp":1558869183359,"user_tz":-330,"elapsed":12350,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}},"colab":{"base_uri":"https://localhost:8080/","height":846}},"source":["for m in net.modules():\n","    if isinstance(m,nn.Conv2d) or isinstance(m,nn.BatchNorm2d) or isinstance(m,nn.Linear):\n","        temp_weight = m.weight.data.cpu().numpy()\n","        dims = temp_weight.shape\n","        temp_weight = temp_weight.flatten()\n","        temp_weight = uniform_quantize(temp_weight, 8)\n","        temp_weight=np.reshape(temp_weight,dims)\n","        m.weight.data = (torch.FloatTensor(temp_weight).cuda())\n","        \n","        temp_bias = m.bias.data.cpu().numpy()\n","        dims = temp_bias.shape\n","        temp_bias = temp_bias.flatten()\n","        temp_bias = uniform_quantize(temp_bias, 1)\n","        temp_bias = np.reshape(temp_bias,dims)\n","        m.bias.data = (torch.FloatTensor(temp_bias).cuda())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 400\n","Number of unique parameters after quantization: 107\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 16\n","Number of unique parameters after quantization: 2\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 16\n","Number of unique parameters after quantization: 11\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 16\n","Number of unique parameters after quantization: 2\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 2304\n","Number of unique parameters after quantization: 131\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 16\n","Number of unique parameters after quantization: 2\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 16\n","Number of unique parameters after quantization: 11\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 16\n","Number of unique parameters after quantization: 2\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 4608\n","Number of unique parameters after quantization: 107\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 32\n","Number of unique parameters after quantization: 2\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 32\n","Number of unique parameters after quantization: 10\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 32\n","Number of unique parameters after quantization: 2\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 468380\n","Number of unique parameters after quantization: 130\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 300\n","Number of unique parameters after quantization: 2\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 3000\n","Number of unique parameters after quantization: 73\n","-------------------------LAYER---------------------------\n","Number of unique parameters before quantization: 10\n","Number of unique parameters after quantization: 2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lQsNHoNyNSCW","colab_type":"text"},"source":["Now that we have replaced the weight matrix with the approximated weight of the nearest cluster, we can test the network with the modified weights."]},{"cell_type":"code","metadata":{"id":"3qYOc_42NSCX","colab_type":"code","outputId":"2bfce1cd-4edc-4658-e75f-82de9a737cf9","executionInfo":{"status":"ok","timestamp":1558869473395,"user_tz":-330,"elapsed":1838,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["testing(net)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Accuracy of the network on the 10000 test images: 94.59 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-sCB4SNmNSCa","colab_type":"text"},"source":["## Non-uniform quantization\n","\n","We have seen in the previous method that we divide the weight space into equally partitioned cluster heads. However, instead of forcing the cluster heads to be equally spaced it would make more sense to learn them. A common and obvious practice is to learn the weight space as a distribution of cluseter centers using k-means clustering. Here, we define a function to perform k-means to the weight values.\n","\n","$$\n","min\\sum_{i}^{mn}\\sum_{j}^{k}||w_{i}-c_{j}||_{2}^{2}\n","$$"]},{"cell_type":"code","metadata":{"id":"GUDAcctdNSCb","colab_type":"code","colab":{}},"source":["num_clusters = 8\n","kmeans = KMeans(n_clusters=num_clusters, random_state=0,  max_iter=500, precompute_distances='auto', verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r2wWh5lbNSCe","colab_type":"code","colab":{}},"source":["def non_uniform_quantize(weights):\n","    print(\"---------------------------Layer--------------------------------\")\n","    print(\"Number of unique parameters before quantization: \" + str(len(np.unique(weights))))\n","    weights = np.reshape(weights,[weights.shape[0],1])\n","    print(weights.shape)\n","    kmeans_fit = kmeans.fit(weights)\n","    clusters = kmeans_fit.cluster_centers_\n","    \n","    for i in range(0,len(weights)):\n","        dist= (clusters-weights[i])**2     \n","        weights[i]=clusters[np.argmin(dist)]\n","        \n","    print(\"Number of unique parameters after quantization: \" + str(len(np.unique(weights))))\n","    \n","    return weights  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"luzXZINVNSCg","colab_type":"text"},"source":["We reset the model and train the network since we had earlier done uniform quantization on the weight already."]},{"cell_type":"code","metadata":{"id":"IYdxVUsvNSCj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"fcdbdcdd-2079-44cf-a3db-00c07a0e5346","executionInfo":{"status":"ok","timestamp":1558977203133,"user_tz":-330,"elapsed":59677,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["reset = True\n","net = training(net, reset)\n","testing(net)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1, Loss: 555.3051, Accuracy: 0.9532\n","Epoch: 2, Loss: 236.4261, Accuracy: 0.9772\n","Epoch: 3, Loss: 192.8441, Accuracy: 0.9798\n","Epoch: 4, Loss: 172.5762, Accuracy: 0.9809\n","Epoch: 5, Loss: 162.5743, Accuracy: 0.9822\n","Test Accuracy of the network on the 10000 test images: 98.40 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WXhYLriUNSCm","colab_type":"text"},"source":["Uniform quantization on the weights and biases"]},{"cell_type":"code","metadata":{"id":"ygTmNfWsNSCm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1181},"outputId":"de82ec9d-0034-454d-966f-a1504fa285f1","executionInfo":{"status":"ok","timestamp":1558977279529,"user_tz":-330,"elapsed":9399,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["for m in net.modules():\n","    if isinstance(m,nn.Conv2d) or isinstance(m,nn.BatchNorm2d) or isinstance(m,nn.Linear):\n","        temp_weight = m.weight.data.cpu().numpy()\n","        dims = temp_weight.shape\n","        temp_weight = temp_weight.flatten()\n","        temp_weight = non_uniform_quantize(temp_weight)\n","        temp_weight=np.reshape(temp_weight,dims)\n","        m.weight.data = (torch.FloatTensor(temp_weight).cuda())\n","        \n","        temp_bias = m.bias.data.cpu().numpy()\n","        dims = temp_bias.shape\n","        temp_bias = temp_bias.flatten()\n","        temp_bias = non_uniform_quantize(temp_bias)\n","        temp_bias = np.reshape(temp_bias,dims)\n","        m.bias.data = (torch.FloatTensor(temp_bias).cuda())"],"execution_count":22,"outputs":[{"output_type":"stream","text":["---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 400\n","(400, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 16\n","(16, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 16\n","(16, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 16\n","(16, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 2304\n","(2304, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 16\n","(16, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 16\n","(16, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 16\n","(16, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 4608\n","(4608, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 32\n","(32, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 32\n","(32, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 32\n","(32, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 468965\n","(470400, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 300\n","(300, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 3000\n","(3000, 1)\n","Number of unique parameters after quantization: 8\n","---------------------------Layer--------------------------------\n","Number of unique parameters before quantization: 10\n","(10, 1)\n","Number of unique parameters after quantization: 8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XAZkRYg9NSCp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0b7b4a67-f805-41d0-960e-90dad7696c68","executionInfo":{"status":"ok","timestamp":1558977281919,"user_tz":-330,"elapsed":2353,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["testing(net)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Test Accuracy of the network on the 10000 test images: 98.24 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AZME62IFNSCr","colab_type":"text"},"source":["### Retraining the network\n","\n","Here we see that 8 clusters are too less in order to maintain the network at the same accuracy since we see almost a 3% drop in performance. One of the solutions is to retrain the network. This helps the other weights to compensate for those weights which on being rounded off to the nearest cluster center have resulted in a drop in performance. Accuracy can be recovered significantly on retraining the network and then non-uniformly quantizing the weights again."]},{"cell_type":"code","metadata":{"id":"hDGjonRNNSCt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"803c6028-485c-45fa-b8bc-9c25fc269155","executionInfo":{"status":"ok","timestamp":1558977453507,"user_tz":-330,"elapsed":59800,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["reset = False\n","net = training(net, reset)\n","#perform non-uniform quantization\n","testing(net)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1, Loss: 156.5617, Accuracy: 0.9828\n","Epoch: 2, Loss: 149.7550, Accuracy: 0.9829\n","Epoch: 3, Loss: 143.9351, Accuracy: 0.9840\n","Epoch: 4, Loss: 141.0685, Accuracy: 0.9845\n","Epoch: 5, Loss: 137.2367, Accuracy: 0.9853\n","Test Accuracy of the network on the 10000 test images: 98.45 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wNL2AuOeNSCx","colab_type":"text"},"source":["### References\n","\n","1. https://arxiv.org/pdf/1412.6115.pdf"]},{"cell_type":"markdown","metadata":{"id":"do82jrSqrJ3R","colab_type":"text"},"source":["#### Please answer the questions below to complete the experiment:"]},{"cell_type":"code","metadata":{"id":"dSxOGoFfi9SW","colab_type":"code","colab":{}},"source":["#@title The k-means quantization used above, clusters all the input data points (features) before training ? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer = \"FALSE\" #@param [\"TRUE\",\"FALSE\"]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPcT0jDuNSCx","colab_type":"code","colab":{}},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good and Challenging me\" #@param [\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e5EaiqxJrOjw","colab_type":"code","colab":{}},"source":["#@title If it was very easy, what more you would have liked to have been added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \" test\" #@param {type:\"string\"}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NiMFoU9NrQM9","colab_type":"code","colab":{}},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"Yes\", \"No\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yrDuolf4rSZC","colab_type":"code","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":126},"outputId":"23bb90da-178c-4bb2-ce21-d8b3fdba1659","executionInfo":{"status":"ok","timestamp":1558977597264,"user_tz":-330,"elapsed":5696,"user":{"displayName":"Arjun Gupta","photoUrl":"https://lh3.googleusercontent.com/-79xPDqhG3Ck/AAAAAAAAAAI/AAAAAAAAAHk/eNdIlCuxOFA/s64/photo.jpg","userId":"06632186555192968294"}}},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id =return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Your submission is successful.\n","Ref Id: 5649\n","Date of submission:  27 May 2019\n","Time of submission:  22:46:57\n","View your submissions: https://iiith-aiml.talentsprint.com/notebook_submissions\n","For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\n"],"name":"stdout"}]}]}